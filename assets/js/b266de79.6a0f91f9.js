"use strict";(globalThis.webpackChunkblog=globalThis.webpackChunkblog||[]).push([[3518],{4369:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"my-2024-reads","metadata":{"permalink":"/my-2024-reads","source":"@site/blog/my-2024-reads.md","title":"My 2024 reads","description":"Peopleware: Productive Projects and Teams","date":"2024-12-25T00:00:00.000Z","tags":[{"inline":true,"label":"books","permalink":"/tags/books"}],"readingTime":3.42,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","title":"Software Engineer","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":"alolis","page":null}],"frontMatter":{"slug":"my-2024-reads","title":"My 2024 reads","date":"2024-12-25T00:00:00.000Z","authors":"alolis","tags":["books"]},"unlisted":false,"nextItem":{"title":"My 2023 reads","permalink":"/my-2023-reads"}},"content":"[![Peopleware: Productive Projects and Teams](./assets/book_covers/peopleware_tom_demarco_timothy_lister.png)](https://www.goodreads.com/book/show/67825.Peopleware)\\n[![The Phoenix Project](./assets/book_covers/the_phoenix_project_gene_kim_kevin_behr_george_spafford.png)](https://www.goodreads.com/book/show/17255186-the-phoenix-project)\\n[![How to Solve It: A New Aspect of Mathematical Method](./assets/book_covers/how_to_solve_it_george_polya.png)](https://www.goodreads.com/book/show/18713393-how-to-solve-it)\\n[![Sapiens: A Brief History of Humankind](./assets/book_covers/sapeniens_a_brief_history_of_humankind_yuval_noah_harari.png)](https://www.goodreads.com/book/show/23692271-sapiens)\\n[![The Art of Shralpinism: Lessons from the Mountains](./assets/book_covers/the_art_of_shralpinism_jeremy_jones.png)](https://www.goodreads.com/book/show/63096355-the-art-of-shralpinism)\\n[![Why Are We Yelling?: The Art of Productive Disagreement](./assets/book_covers/why_are_we_yelling_buster_benson.png)](https://www.goodreads.com/book/show/44279111-why-are-we-yelling)\\n\\n\x3c!--truncate--\x3e\\n\\n* **[5/5/] Peopleware: Productive Projects and Teams**: If you are a manager in a software company then you need to read this NOW. The important lesson here is that people are the core of any development process, something that a lot of managers forget most of the time. The book was written in 1987 and still applies today.\\n* **[5/5/] The Phoenix Project**: Loved it. I started reading it a couple of years ago and left it in the middle so decided to start from the beginning again. I am glad I did that because it was definitely worth my full attention. I am pretty sure that anyone long enough in IT will appreciate it and resonate with Bill\'s (the hero of the book) daily \\"adventures\\" in the crazy world of technology mixed with business. I also recommend reading *The Goal, by Eliyahu M. Goldratt* which I believe it\'s what basically inspired the writing of this book as well.\\n* **[4/5] How to Solve It: A New Aspect of Mathematical Method**: A very insighful book which applies even today, even if it\'s written in 1945 and it\'s around mathematics and geometry. Although it gets a bit repetetive, it\'s definitely worth it since it\'s filled with examples in order to help the reader understand its underlying framework for problem solving. Polya manages to translate his approach from the mathematics field to other domains that apply to our daily lifes.\\n* **[4/5/] Sapiens: A Brief History of Humankind**: A VERY complex and extensive topic that I think the author manages to summarize it pretty well in 500 pages and keeps the reader engaged. Lot\'s of interesting information and ideas, and even though I am sceptical about some, the fact that it does give an interesting perspective to human history is definitely intriguing and worth the read. The central idea around the book is that the humans did a huge mistake by turning from from being hunter-gatherers to agriculture which made them settle down, lose important knowledge and skills that all anchestors posesed and made us more miserable and harsh. Really enjoyed it, definitely recommend.\\n* **[3/5] The Art of Shralpinism: Lessons from the Mountains**: When a master speaks, you listen. Jeremy Jones is definitely a master in snowboarding and mounteneering and I was anxious to read his book. I really, really wanted to love it but I am afraid, it failed short to my expectations. First of all, there are a lot of story sections which due to the chosen font and background, are either very hard to read or compltely unreadable. Secondly, I was expecting to gain some deep knowledge which someone can only gain by doing it, and even though Jeremy Jones has been out there for a long time and have gained years and years of experience, he has failed to transfer at least some of it. Although there are tips and technical notes in the book here and there, in general it felt a little bit vague. Sorry Jeremy, I still respect you deeply for doing what you are doing, but for the next book, get a writing consultant!\\n* **[1/5] Why Are We Yelling? The Art of Productive Disagreement**: A very interesting question which the author has failed to answer. At first, the book looks promising but as you keep going the author starts rambling about gun violence, politics and other completely unrelated things with the topic. Do not waste your time."},{"id":"my-2023-reads","metadata":{"permalink":"/my-2023-reads","source":"@site/blog/my-2023-reads.md","title":"My 2023 reads","description":"Code: The Hidden Language of Computer Hardware and Software","date":"2023-12-26T00:00:00.000Z","tags":[{"inline":true,"label":"books","permalink":"/tags/books"}],"readingTime":7.02,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":null,"page":null}],"frontMatter":{"slug":"my-2023-reads","title":"My 2023 reads","date":"2023-12-26T00:00:00.000Z","author":"Alexander Lolis","author_url":"https://github.com/alolis","author_image_url":"https://avatars.githubusercontent.com/u/82233?v=4","tags":["books"]},"unlisted":false,"prevItem":{"title":"My 2024 reads","permalink":"/my-2024-reads"},"nextItem":{"title":"My 2022 reads","permalink":"/my-2022-reads"}},"content":"[![Code: The Hidden Language of Computer Hardware and Software](./assets/book_covers/code_charles_petzold.png)](https://www.goodreads.com/book/show/44882.Code)\\n[![Good Strategy Bad Strategy: The Difference and Why It Matters](./assets/book_covers/good_strategy_bad_strategy_richard_rumelt.png)](https://www.goodreads.com/book/show/11721966-good-strategy-bad-strategy)\\n[![Refactoring UI](./assets/book_covers/refactoring_ui_adam_wathan_steve_schoger.png)](https://www.goodreads.com/book/show/43190966-refactoring-ui)\\n[![The Goal: A Process of Ongoing Improvement](./assets/book_covers/the_goal_eliyahu_n._goldratt_jeff_cox.png)](https://www.goodreads.com/book/show/113934.The_Goal)\\n[![Seven and a Half Lessons About the Brain](./assets/book_covers/seven_and_a_half_lessons_about_the_brain_lisa_feldman_barrett.png)](https://www.goodreads.com/book/show/56034793-seven-and-a-half-lessons-about-the-brain)\\n[![Phoenix in Action](./assets/book_covers/phoenix_in_action_geoffrey_lessel.png)](https://www.goodreads.com/book/show/42114632-phoenix-in-action)\\n[![RxJS in Action](./assets/book_covers/rxjs_in_action_paul_daniels_luis_atencio.png)](https://www.goodreads.com/book/show/30724353-rxjs-in-action)\\n[![Programming Ecto](./assets/book_covers/programming_ecto_darin_wilson_eric_meadows.png)](https://www.goodreads.com/book/show/40582814-programming-ecto)\\n[![The Art of Readable Code: Simple and Practical Techniques for Writing Better Code](./assets/book_covers/the_art_of_readable_code_dustin_boswell_trevor_foucher.png)](https://www.goodreads.com/book/show/8677004-the-art-of-readable-code)\\n[![CTO Excellence in 100 Days: Becoming the Leader Your Company Deserves](./assets/book_covers/cto_excellence_in_100_days.png)](https://www.goodreads.com/book/show/113847910-cto-excellence-in-100-days)\\n[![Nobody Wants to Read Your Sh*t: Why That Is And What You Can Do About It](./assets/book_covers/nobody_wants_to_read_your_shit_steven_pressfield.png)](https://www.goodreads.com/book/show/30556551-nobody-wants-to-read-your-sh-t)\\n[![Rich Dad, Poor Dad](./assets/book_covers/rich_dad_poor_dad_robert_kiyosaki.png)](https://www.goodreads.com/book/show/69571.Rich_Dad_Poor_Dad)\\n\\n\x3c!--truncate--\x3e\\n\\n* **[5/5/] Code**: This book was in my bookshelf for some time now and I finally got around it. Although most of the concepts were known to me this is the first time that I felt everything coming together and got plenty of \\"Aha!\\" moments. I must admit, that a couple of chapters got too deep technically and I\'ve only read them without trying to fully understand them, but they were definitely worth going through them. This book is a **MUST** for anyone into computer science\\n* **[4/5/] Good Strategy Bad Strategy**: I really enjoyed this book and how it defines strategy and makes a clear distinction between a good and a bad one. Lots of good real world examples and actionable ideas. I felt that a few sections could have been more compact but it definitely wasn\'t tiresome. I strongly recommend reading it\\n* **[4/5] Refactoring UI**: This book is not only for designers, but for developer as well. In fact, I would probably say that a developer needs to read this more than a designer. It definitely gives an interesting pespective on design and how to keep things clean and simple, to get things going instead of losing yourself into too much details. I strongly recommend reading it\\n* **[4/5] The Goal**: A very well written process improvement novel. The story was very realistic  with practical lessons that can be applied to the real world. For me, an important lesson here was that open-minded teams which want to solve problems and improve, will find the way by communicating well and by being willing to go through an iterative process. The story will probably be more interesting to people that are in the manufacturing industry but in general I find it useful for anyone that deals with process flows. It was a breez reading it and if you liked it and you are in IT, I also strongly recommend reading *The Phoenix Project* by Gene Kim\\n* **[4/5] Seven and a Half Lessons About the Brain**: A short and very interesting book on human brain, a subject that I find fascinating. Two things really hit me when I was reading this book. The first one is the way the book phrases the fact that our brain can create reality and that we live in a made up world. The second one, which it\'s the first time I read about it although it seems it is known in this circle for some time now, is that we do not have a triune brain in which we can blame our primitive behavior when e.g get angry, but we simple have a differently evolved brain from other species and our irational thoughts can simple be attributed to body budgeting reasons. A very interesting idea that if accepted world wide, it will affect society at it\'s core, especially in law cases. If you are interested about the human brain, then definitely read this\\n* **[4/5] Phoenix in Action**: A nice and easy read about the Phoenix framework which gives you a good overview with detailed examples of what is possible with it. I feel that the Elixir sections could have been more compact in order to make you read an Elixir-specific book that covers the subject better and maybe write more about of Phoenix, but I definitely didn\'t mind. This book is a good entry point for learning about the framework but things are moving within the Phoenix community and some code/techniques might not apply at the time you read it, so I strongly recommend that you also have a look at the very well written, [official Phoenix documentation](https://hexdocs.pm/phoenix/Phoenix.html)\\n* **[4/5] Programming Ecto**: A well written and helpful resource about Ecto. Altough *Phoenix in Action* had a lot of information about it, I felt that I had some gaps which this book definitely filled. Lot\'s of practical examples. What I also liked about the book is that it specifically covered real scenarios which in my opinion are pretty common. I strongly recommend reading it after *Phoenix in Action*\\n* **[4/5] RxJS in Action**: Reactive programming is a very interesting and powerful programming technique, especially in UI where a lot of things are happening asynchronously at the same time,  and this book will definitely help you get into it by using RxJS. Lot\'s of real world examples and practical ideas. Some sections were a little bit more dense and more tiring than others but definitely worth the trouble reading them. I feel that some examples which showed a bad way to achieve something were missing their counterpart, the good way to actually do it and not just explaining it in theory. I definitely feel though that I now know much more about RxJS than before reading it\\n* **[3/5] The Art of Readable Code**: I have mixed feelings about this book since I am not sure to whom is addressed. Lot\'s of legit advice and ideas, but an experienced developer should already know all of this. A junior developer however, will not, but some of the advice in here might not be understood until the developer actually experiences it in a real code base. I definitely recommend that any junior developer should read this, and perhaps a more senior should go through it and refresh what they already know. I mostly agree with everything described in here but I would really love to if the author showed some functional programming as well \\n* **[3/5] CTO Excellence in 100 Days**: I am not even sure if the book is worth the 3/5 I gave it. It\'s probably somewhere between 2 and 3. It was very basic and it was mostly about people having lack of confidence into becoming CTOs than actually being CTOs. I believe there are better books out there that can enhance your understanding of a technical role better, especially the role of a CTO. For example, I found *The Startup CTO\'s handbook* by Zach Goldberg much much better. I wouldn\'t recommend this one\\n* **[2/5] Nobody Wants to Read Your Shit**: A very mediocre book with just a catchy title. I didn\'t even manage to finish it. Stopped at around 2/3 of the book. Even if there was some solid advice here and there, it was VERY basic and kinda boring. Don\'t waste your time\\n* **[1/5] Rich Dad, Poor Dad**: This book is just, sad. Among other things, the author basically says to pray on the weak in order to create wealth. Even if I completely put my feelings \\naside and judge the book more objectively, it only contains repetetive information without any actionable advice. Just a generic \\"learn what is an asset and what is a liability\\" mantra that is thrown around in most of the pages. I really do not understand why this book is a best seller. Definitely learn about investing and finance, just not from this. He did manage to do something right though; to properly market the book and take our money"},{"id":"my-2022-reads","metadata":{"permalink":"/my-2022-reads","source":"@site/blog/my-2022-reads.md","title":"My 2022 reads","description":"Four Thousand Weeks: Time Management for Mortals","date":"2022-12-25T00:00:00.000Z","tags":[{"inline":true,"label":"books","permalink":"/tags/books"}],"readingTime":0.99,"hasTruncateMarker":false,"authors":[{"name":"Alexander Lolis","title":"Software Engineer","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":"alolis","page":null}],"frontMatter":{"slug":"my-2022-reads","title":"My 2022 reads","date":"2022-12-25T00:00:00.000Z","authors":"alolis","tags":["books"]},"unlisted":false,"prevItem":{"title":"My 2023 reads","permalink":"/my-2023-reads"},"nextItem":{"title":"Authorization in a microservices world","permalink":"/authorization-in-a-microservices-world"}},"content":"[![Four Thousand Weeks: Time Management for Mortals](./assets/book_covers/four_thousand_weeks_oliver_burkeman.jpg)](https://www.goodreads.com/book/show/54785515-four-thousand-weeks)\\n[![The Evolution Of Desire: Strategies of Human Mating](./assets/book_covers/the_evolution_of_desire_david_buss.jpg)](https://www.goodreads.com/book/show/27491.The_Evolution_Of_Desire)\\n[![Laws of UX: Using Psychology to Design Better Products & Services](./assets/book_covers/laws_of_ux_jon_yablonski.jpg)](https://www.goodreads.com/book/show/53601155-laws-of-ux)\\n[![Staying Alive in Avalanche Terrain](./assets/book_covers/staying_alive_in_avalanche_terrain_bruce_temper.jpg)](https://www.goodreads.com/book/show/1924.Staying_Alive_in_Avalanche_Terrain)\\n[![Atomic Habits: An Easy & Proven Way to Build Good Habits & Break Bad Ones](./assets/book_covers/atomic_habits_james_clear.jpg)](https://www.goodreads.com/book/show/40121378-atomic-habits)\\n[![The Choice: Embrace the Possible](./assets/book_covers/the_choice_edith_eger.jpg)](https://www.goodreads.com/book/show/30753738-the-choice)\\n[![Moneyland: Why Thieves and Crooks Now Rule the World and How To Take It Back](./assets/book_covers/moneyland_oliver_bullough.jpg)](https://www.goodreads.com/book/show/39979237-moneyland)\\n[![Strong Advice: Zuby\'s Guide to Fitness for Everybody](./assets/book_covers/strong_advice_zuby_udezue.jpg)](https://www.goodreads.com/book/show/52911233-strong-advice)\\n[![Practical Doomsday: A Sensible Field Guide to Surviving Disasters](./assets/book_covers/practical_doomsday_michal_zalewski.jpg)](https://www.goodreads.com/book/show/58680286-practical-doomsday)\\n[![Building a Second Brain: A Proven Method to Organize Your Digital Life and Unlock Your Creative Potential](./assets/book_covers/building_a_second_brain_tiago_forte.jpg)](https://www.goodreads.com/book/show/59616977-building-a-second-brain)"},{"id":"authorization-in-a-microservices-world","metadata":{"permalink":"/authorization-in-a-microservices-world","source":"@site/blog/authorization-in-a-microservices-world.md","title":"Authorization in a microservices world","description":"Authorization? How hard can it be? I am pretty sure that others have already solved it. We are not the first ones doing microservices. It should be easy to integrate what\'s already out there.","date":"2022-03-20T00:00:00.000Z","tags":[{"inline":true,"label":"microservices","permalink":"/tags/microservices"},{"inline":true,"label":"authorization","permalink":"/tags/authorization"},{"inline":true,"label":"architecture","permalink":"/tags/architecture"},{"inline":true,"label":"battlefield","permalink":"/tags/battlefield"},{"inline":true,"label":"development","permalink":"/tags/development"}],"readingTime":25.13,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":null,"page":null}],"frontMatter":{"slug":"authorization-in-a-microservices-world","title":"Authorization in a microservices world","date":"2022-03-20T00:00:00.000Z","author":"Alexander Lolis","author_url":"https://github.com/alolis","author_image_url":"https://avatars.githubusercontent.com/u/82233?v=4","tags":["microservices","authorization","architecture","battlefield","development"]},"unlisted":false,"prevItem":{"title":"My 2022 reads","permalink":"/my-2022-reads"},"nextItem":{"title":"My 2021 reads","permalink":"/my-2021-reads"}},"content":"> Authorization? How hard can it be? I am pretty sure that others have already solved it. We are not the first ones doing microservices. It should be easy to integrate what\'s already out there. \\n> \\n> \\\\- Everybody when they started designing their microservices, before they cried\\n\\n**Fine-grained authorization in microservices is hard.** Definitely not impossible, but hard. You would expect that a more standardized, all-around, full-proof solution is out there, but I am afraid there isn\'t. It\'s a complex matter and depending on what you are building, implementation varies.\\n\\nYou will probably start with a boolean `admin` flag in your `User` model and then you will replace it with a `role` field, as we all did. However, as things progress and the business model becomes more and more complex, so do the solutions that we need to implement in order to deal with that complexity.\\n\\nBut how do you actually go **from a simple flag** to **Role Based Access Control (RBAC)** and then to **Attribute Based Access Control (ABAC)**, especially in a microservices environment? In the following post I hope to help you get there.\\n\\n*(UPDATE: 02/04/2022): This article made it to the HackerNews frontpage and some interesting comments can be found [here](https://news.ycombinator.com/item?id=30878926). Feel free to participate!*\\n\\n\x3c!--truncate--\x3e\\n\\n## The monolith\\n\\nThe first time I had to deal with a more complex authorization system was in a **monolithic CMS application** written in `PHP 5.x`, on top of **Zend Framework** (now known as Laminas Project), with a **MySQL** backend, a billion years ago. The app was following the hot and trendy **Model-View-Controller (MVC)** pattern and the requirement in the specific project was, except hierarchical role-based access control (H-RBAC), to have more fine-grained permissions as well as to be able to answer two specific questions: \\n\\n1. **Can the user do X on a Y resource if their role allows it or if the resource is owned by them?**\\n2. **Can the user A, with role X, access the data of user B, that has the same or a higher level role?**\\n\\n(For the sake of simplicity and because it does not really offer any extra value, I will skip the implementation details of question 2 and I will just use question 1 for my example below).\\n\\nAfter thinking about the situation, and the fact that we had a VERY specific problem to solve, that I KNEW it wouldn\'t change in the future, and ALL the data models were associated with a single user, this is what a very simplified version looked like (forgive my PHP, it\'s a bit rusty):\\n\\n```php title=controllers/items_controller.php\\nclass ItemsController extends Zend_Controller_Action {\\n  // ...omitted code\\n  \\n  public function listAction() {\\n    $page = $this->_getParam(\'page\', 1);\\n    $orderBy = $this->_getParam(\'order_by\', \'created_at\');\\n    $order = $this->_getParam(\'order\', \'desc\');\\n    \\n    $filters = array(\'drafts\' => false);\\n    $user = Session::getUser();\\n    \\n    if ($user->isAuthorized(\'can_list_drafts\', \'items\')) {\\n      $filters[\'drafts\'] = $this->_getParam(\'drafts\', false);\\n    \\n    $result = ItemModel::find($filters, $page, $orderBy, $order);\\n  \\n    return $result;\\n  }\\n  \\n  public function destroyAction() \\n  {\\n    $itemId = $this->_request->getParam(\'itemId\');\\n    $item = ItemModel::findById($itemId);\\n  \\n    if (!$item) {\\n      throw new ItemNotFoundException();\\n    }\\n    \\n    $user = Session::getUser();\\n    \\n    if (!$user->hasRoleOrSelfPermissionOn(\'can_delete_items\', \'can_delete_own_items\', \'items\', $item)\\n      throw new AuthorizationException();\\n    \\n    $result = $item->destroy();\\n    \\n    return $result;\\n  }\\n  \\n  // ... rest of code\\n}\\n```\\n\\n```php title=models/user.php\\nclass User {    \\n  // ...omitted code\\n  \\n  public isAuthorized($permission, $resource) \\n  {\\n    // The ACL singleton class is a wrapper around Zend ACL which is a module that provides you\\n    // with hierarchical, role based, access control lists which you can query and check\\n    // if a role has the requested permission on a resource.\\n    if (ACL::getInstance()->isAuthorized($this->role, $permission, $resource)\\n      return true;      \\n\\n    return false;\\n  }\\n  \\n  public hasRoleOrSelfPermissionOn($rolePermission, $selfRolePermission, $resource, $model)\\n  {\\n    if ($this->isAuthorized($rolePermission, $resource) {\\n      return true;\\n    }\\n    elseif ($model.userId == $this.id) {\\n      if ($this->isAuthorized($selfRolePermission, $resource))\\n        return true;\\n    }\\n    \\n    return false;\\n  }\\n  \\n  // ...rest of code\\n}\\n```\\n\\nA few things are going on above:\\n\\n1. **The decision point and enforcement of authorization is happening in the controller, getting mixed with application code that does not care about all these things**, plus, it makes it harder to test. We do not want that. We want our controllers to be lean (in terms of responsibilities) and just return appropriate responses which are related to what was requested in the first place. \\n2. In `listAction` we need to check individual filters in order to decide if the user is authorized to use them or not. If multiple filters exist that need to be checked, the controller will become too messy, too fast.\\n3. The application data that the authorization requires (in this case `$item`) are locally available and easily loaded with our `ItemModel` class. As you will understand later, loading necessary application data is the biggest pain point.\\n4. The `User` class is suddenly coupled with authorization. It shouldn\'t. It should only care about the user entity itself, like the class name implies.\\n5. `hasRoleOrSelfPermissionOn` makes the assumption that all models have a `userId` field which means that we should know beforehand that this will be true (forever) or else the function will not work as expected. \\n\\n**The authorization code is tedious, poluting the controllers, and error prone**. However, we were also lucky because this was the ugliest it could get (based on project requirements) and therefore it was acceptable (or at least we persuaded ourselves that it was), instead of pushing to a more complex solution. If, for example, there was the requirement of checking multiple model attributes (or attributes from different models), depending on the controller action, then `hasRoleOrSelfPermissionOn` wouldn\'t be able to cover everything and the controllers would immediately become much messier. It did serve us well back then but I no longer like it because avoiding tangling code at some point became a priority.\\n\\n**What I am describing above is not inherent to monoliths.** The same implementation could have been done in a microservice (and I have seen it in multiple occasions, with everything done in the controllers) if the application data that the authorization mechanism required, lived under the same roof. But more on that later.\\n\\n#### So, what could we have done to improve the above situation?\\n\\nPush the authorization code higher up in the stack. That would mean that you could push it to somewhere like a `middleware`, as most web frameworks call it, which is basically code that is executed before your controllers. And this, is where the fun begins and a whole new set of implementation problems rises!\\n\\nBut before we dive into that, we need to think about our authorization flow in a more abstract level.\\n\\n## Authorization flow overview\\n\\nSo, what would this authorization mechanism look like in order to not force a single architecture but be more flexible instead? The following diagram will give you an idea:\\n\\n<div style={{textAlign: \\"center\\"}}>\\n\\n![Authorization Overview](./assets/images/authorization_architecture_overview.jpg)\\n\\n</div>\\n\\n**The flow goes like this:**\\n\\n1. User requests to view record A.\\n2. The request is intercepted by the **Policy Enforcement Point (PEP)**. This is usually a **middleware**, or generally speaking, a layer in your stack, as high as possible, in order for the request to stop right there in case it\'s not authorized, instead of allowing it to travel deeper in the system.\\n3. **PEP** makes a request to the **Policy Decision Point (PDP)** in order to figure out whether or not the request is authorized to move forward. PDP will probably be a library that keeps track of roles, permissions and resources and expose an interface in order to query it and get a boolean answer whether or not someone can do something on a resource.\\n4. **PDP** *might* need extra information in order to decide if the request should be allowed or denied so it needs to ask the **Policy Information Point (PIP)** for that extra information. That extra information can be retrieved from a database, from a flat file, from an external service or from any other source you need. PIP could be just another library which PDP can use internally if it needs to.\\n5. **PIP** loads the extra information and returns it to the PDP.\\n6. **PDP**, in combination with the extra information it got from PIP, evaluates the defined policy (which can be stored anywhere you like, e.g. database or flat file), and decides whether or not the request has access to the underlying resource based on what the policy says. \\n7. The answer **is returned to PEP**, which either allows or denies the request to move forward.\\n\\nOn the diagram above there is another piece, **the Policy Administration Point (PAP)**. This is basically an optional interface that helps you manage the policies. It can be anything, a web interface, a command line tool, a desktop GUI or you can just skip it entirely if you do not want to provide it and do everything manually instead.\\n\\n## Architectures\\n\\nNow that we have defined our authorization flow, let\'s go through a few real world architectures together. All the following architectures include a diagram and within this diagram I make clear what plays which role based on what I showed you earlier.\\n\\n### With an authorization service\\n\\nSo, you are there thinking, I am doing microservices, right? So the logical thing to do is to implement an **authorization service** and everybody would be able to use that and keep your precious service boundaries, right? **WRONG**. Your hell, has just begun!\\n\\n<div style={{textAlign: \\"center\\"}}>\\n\\n![Overview](./assets/images/authorization_architecture_authorization_service.jpg)\\n\\n</div>\\n\\n**How will PIP fetch the application data that PDP needs?**\\n\\n1. **Direct DB reads:** I am pretty sure someone will suggest this, and then will say, *\\"I know we shouldn\'t be doing this in microservices but let\'s just make this exception\\"*, but that\'s how all big problems are created. With a small exception here, with another one there, and then things start to blow up, or even worst, become unmaintenable. Direct DB reads, outside the domain of each service, is a bad idea and it will be obvious to you why on the first schema change. Please don\'t be lazy and just say no to this.\\n2. **Attach all the extra data to the authorization service call:.** By doing this you will probably increase the network traffic and you might cause a bottleneck on the service if every request has a lot of data attached. However, these - manageable - disadvantages are not even my main concern with this approach. My main concern is the fact that the caller now needs to know the authorization logic that will be used internally by the authorization service in order to send the appropriate data. This will probably lead to callers sending more data than they should, or not removing data from the call whenever a policy changes, \\"just to be sure\\", and as a result the code maintenance will become harder. Even in a perfect world, were the data are ALWAYS exactly what is needed, the extra work of choosing the data is a burden that the caller should not have.\\n3. **Keep a copy of the data the authorization service needs:** This basically means syncing the data from all the other services, to the authorization service database, with a generic model that will be able to fit (in terms of a schema) everything. I can tell you right now that, this is difficult to achieve, especially if the syncing is experiencing network delays and/or conflicts. There are others who are doing this (check [Google Zanzibar](https://research.google/pubs/pub48190/)), but for most mortal companies I think dealing with the complexities of syncing on your first implementation, is an overkill. Besides, even Zanzibar is not a silver bullet and it\'s higly opinionated with its models, so you might need to build extra parts that communicate with it in order to achieve what you want. \\n\\n\\n### With an authorization service and a data service\\n\\n<div style={{textAlign: \\"center\\"}}>\\n\\n![Overview](./assets/images/authorization_architecture_authorization_and_data_service.jpg)\\n\\n</div>\\n\\nThis is probably the most complex architecture but it definitely clears things up a bit. If the data state and the mutations are all handled by the same layer (a data service), and all other services use that layer, it\'s like they have direct access to the database and the PIP can now fetch whatever it needs.\\n\\nPersonally, I like this architecture because now there is a very clear seperation of who is doing what, even if it means that more code will be required in order to set it up. Building a data service is beyond the scope of this post so I will just keep it simple and say that you shouldn\'t start with this, unless you already have a data service implemented or if you have other needs for it that go beyond authorization.\\n\\n#### Variations\\n\\nThere are a couple of variations with this architecture that I would like to mention since someone might find them interesting.\\n\\n**Instead of doing the authorization within each internal service, you could do the authorization at the API Gateway.** You can use an authorization middleware within the API Gateway in order to communicate with the authorization service, or, you can even get rid of it completely and communicate with the data service directly from the middleware.\\n\\n<div style={{textAlign: \\"center\\"}}>\\n\\n![Overview](./assets/images/authorization_architecture_api_gateway_data_service.jpg)\\n\\n</div>\\n\\nThis has the advantage of stopping the request as early as possible before it has the chance to reach the internal services. In general, I like that idea.\\n\\nHowever, it also has a couple of disadvantages: \\n\\n1. When services make internal calls, they will be bypassing the authorization checks. It might be acceptable in your case but personally I do not like it. I want each service to allow only what is expected and nothing more. You could enforce in your implementation to make all the calls go through the API Gateway but then you increase the network latency and you lose all the advantages of actually having an internal network.\\n2. API Gateway will need to have all the application data loaders (for PIP) implemented there and things might get messy if you are implementing too much. Especially if you have a lot of services you might be changing API Gateway too often for reasons unrelated with the service itself.\\n\\n### With an authorization middleware and library per service\\n\\n<div style={{textAlign: \\"center\\"}}>\\n\\n![Overview](./assets/images/authorization_architecture_service_library.jpg)\\n\\n</div>\\n\\nIn my opinion **this is probably a good balance between complexity and a scalable solution**. You basically keep the authorization logic in each service and each service is responsible for the authorization rules of its own domain.\\n\\nOne thing you will probably need is to have the common code implemented as a library (or libraries) since it will be shared among all services but it shouldn\'t be a problem. Just make sure you cover it with enough tests!\\n\\nThe real question with this approach is; **how homogeneous is your system**? If it\'s 100% then you are in luck. You will only need to implement (or find) everything you need once. if it\'s not, you will need to do it for every different language you are using in your system. Even though there are plenty of libraries out there, depending on your system details, they might not integrate very well or they might be missing a couple of features that you might need. Before you are too eager to implement your own, make sure if an existing solution covers your needs. If it does not, maybe you can get away with it by doing a few changes on your side, or by adding those missing features to the library you found. Whatever you do, take the time to decide carefully.\\n\\n\\n## Implementation\\n\\n### RBAC\\n\\nIf you are doing RBAC, then implementing this is straight forward and clean. You just need a middleware (PEP) in which you must check if the user role (usually attached to a JWT that comes with the request) has access to the specified route path. The policies can easily be stored in a database or a configuration file, load them upon service initialization and let the RBAC library (PDP) that you will use do its work from within your middleware. In this case, no PIP is required.\\n\\nThere are a lot of good solutions out there for RBAC, for any modern web framework from any language, so I will not go into details about this, but I just wanted to briefly mention it. **The only tip I do wanna share though, in case you are implementing something custom**, is that the **resource** in your policies will probably be the **regex route path** and the **permission** will be the **HTTP verb** (`GET`, `DELETE`, etc). By doing that, you can easily get the route path from within the middleware and use a regex route matcher library to check if the resource is a match.\\n\\n### RBAC/ABAC\\n\\nSo let\'s assume that you go with option 3, with an authorization middleware and library per service. How would such implementation look like?\\n\\nThe following implementation approach is neither the best, nor the only one. It is however applicable to the real world and that\'s what is important for me. **What we are basically trying to answer with our implementation is:**\\n\\n1. **How will my authorization mechanism load the necessary application data it needs?**\\n2. **How will I express my policies, in a non confusing way, and be able to access dynamically loaded data from within those policies?**\\n\\nBy answering the above questions we will also be able to provide a better answer back to our friend *the monolith* and its question, *how will we allow a user to do X on Y resource if their roles allows it, or if it\'s owned by them?*\\n\\nThe example is written in `Node.js`, but I am confident you can do something similar in any web framework of your choice. Also, please do keep in mind that I have omitted a lot of code and kept a flat structure in order to try to reduce any confusion with unecessary implementation details. I understand that it can be frustrating but I will try to explain in detail what everything is supposed to do.\\n\\n```js title=server.js\\nimport express from \'express\'; // express is a web framework for Node.js \\nimport logger from \'/your/logger\';\\nimport {\\n  AccessControl, \\n  ROLE, \\n  PREDICATE\\n} from \'/your/access/control/lib\';\\n\\n// `express.js` router handler for listing items and assigned to route `GET /items`. \\n// The assignment is done in our `routesObject` further below.\\nasync listItemsHandler(res, req, next) {\\n  const items = await ItemModel.find(req.query);\\n  \\n  // ... rest of handler; no authorization checks required \\n}\\n\\n// `express.js` router handler for getting a specific item and assigned to route `GET /items/:id`. \\n// The assignment is done in our `routesObject` further below.\\nasync getItemHandler(res, req, next) {\\n  const {id} = req.params;\\n  \\n  const item = await ItemModel.findById(id);\\n  \\n  if (!item) {\\n    throw new ItemNotFoundError();\\n  }\\n  \\n  // ... rest of handler; no authorization checks required\\n}\\n\\n/*\\n  This is a function that represents an `express.js` middleware. It\'s basically code that will run BEFORE \\n  the `listItemsHandler` and the `getItemHandler` implemented above. The middleware acts as the PEP \\n  and  internally uses our access control library in order to decide if it should allow a request or not.\\n  \\n  Check here for extra info on middlewares: https://expressjs.com/en/guide/using-middleware.html\\n*/\\nfunction authorizationExpressMiddleware(request, response, next()) {\\n  // Get the user object from the JWT token that is attached to the request.\\n  // Usually this happens within a middleware higher up in the middleware chain.\\n  const user = request.locals?.user? || null;\\n  const userRole = request.locals?.user?.role? || ROLE.GUEST;\\n\\n  // This is just an object with data that we want to pass to our access control library that is related\\n  // with this request. Everything in this object will be accessible by specifying the appropriate \\n  // object path in the `conditions` key of our policy definitions as we will see later.\\n  const context = {\\n    user,\\n    request\\n  };\\n\\n  const action = request.method; // GET, DELETE, PUT, etc\\n  const resource = path.join(request.baseUrl, request.route.path); // e.g. /items/:id\\n\\n  // Check if the current request is authorized, by also including our `context` object. \\n  const isAuthorized = await accessControl\\n    .withContext(context)\\n    .can(userRole, action, resource);\\n    \\n  // If the request is authorized, then pass the control to the next middleware in the chain.\\n  if (isAuthorized) {\\n    return next(); \\n  }\\n  \\n  // Request is UNAUTHORIZED. Set the HTTP response status and stop the rest of the middleware \\n  // chain from executing by returning an error. The request will stop here.\\n  response.status(401); // Unauthorized\\n  next(new AuthorizationError());\\n}\\n\\n/*\\n  Initialization function for our access control library. This is an imaginary custom PDP library\\n  that internally uses an imaginary custom PIP library. Using the PIP part of the access control \\n  library should be optional.\\n*/\\nfunction initAccessControl(endpointsObject) {\\n  // PIP loader function in order to load a specific item and provide to\\n  // the access control library the extra information it needs.\\n  const pipItemLoader = async (itemId) => {\\n    const item = await ItemModel.findById(itemId);\\n    \\n    if (item) {\\n      return item; \\n    }\\n    \\n    return null;\\n  }\\n\\n  // Initialize the access control library with two roles. The library should be able \\n  // to support hierarchical roles in order to inherit permissions from a parent role \\n  // instead of repeating them, just like below.\\n  const roles = [{\\n    name: ROLE.USER\\n  }, {\\n    name: ROLE.ADMIN\\n    inherits: [ROLE.USER]\\n  }];\\n  \\n  const accessControl = new AccessControl(roles);\\n  \\n  // Add our loader to the access control library in order to be able to use it internally when necessary.\\n  accessControl.addLoader(PIP_LOADER_TYPE.ITEM, pipItemLoader)\\n  \\n  // `buildPermissions` is a custom utility function that parses the `accessControl` key object value from \\n  // our endpoints object and creates a list of permission objects, formatted the way our access\\n  // control library expects them.\\n  const permissions = buildPermissions(endpointsObject);\\n\\n  accessControl.addPermissions(permissions);\\n\\n  return accessControl;\\n}\\n\\n// The following object contains everything we need to describe all the exposed routes. Within the object,\\n// we have also embedded our authorization policies via the `accessControl` key. Within this key, we specify\\n// which role can do what and under which conditions.\\nconst routesObject = {\\n    middlewares: [authorizationExpressMiddleware],\\n    endpoints: {\\n     \'/items\': {\\n      \'/\': {\\n        GET: {\\n          handler: listItemsHandler,\\n          accessControl: {\\n            permissions: [{\\n              role: ROLE.USER,\\n              // The \'user\' role can only list items which the `user_id` filter matches the user who request them.\\n              condition: {predicate: PREDICATE.EQUAL, args: [\'$.request.query.user_id\', \'$.user.id\']}\\n            }, {\\n              role: ROLE.ADMIN,\\n              // The admin role can list items with any filters they like.\\n              condition: * // Any filter is allowed\\n            }]\\n          }\\n        },\\n        \'/:id\': {\\n          GET: {\\n            handler: getItemHandler,\\n            accessControl: {\\n              loader: {fn: PIP_LOADER_TYPE.ITEM, args: [\'$.request.params.id\']},\\n              permissions: [{\\n                role: ROLE.USER,\\n                // The \'user\' role can only get an item that is owned by the user who requested it.\\n                condition: {predicate: PREDICATE.EQUAL, args: [\'$.resource.userId\', \'$.user.id\']}\\n              }]\\n            }\\n          }\\n        }\\n      },\\n     }\\n    }\\n  }\\n};\\n\\n// Initialize access control and our app.\\nconst accessControl = initAccessControl(routesObject.endpoints);\\nconst app = express();\\n\\n// `buildRoutes` is a custom utility function that parses the routes object and adds all the specified routes \\n// to our express.js router by also associated them with the respective handler. The function will also apply\\n// the `middlewares` array from the object to all routes which means that each request will need to go\\n// through our authorization middleware.\\n//\\n// Check the express.js router here: https://expressjs.com/en/guide/routing.html\\nbuildRoutes(app, routesObject);\\n\\napp.listen(3000, () => {\\n  logger.info(`kitten app listening at http://localhost:3000`)\\n})\\n\\n```\\n\\nI tried to keep the example code as succinct as possible in order for everyone to understand, even if they are not familiar with `Node.js`. The important take from the code above is that you *could* use an object to describe your policies, along with your routes, and pass values to those policies by expressing paths from dynamically loaded data that can be used during the evaluation step within our access control library. \\n\\nYou have probably noticed that in the `condition` key some weird stuff are happening in the `args` that are prefixed with `$`. What is happening there is that I am using [JSON path syntax](https://restfulapi.net/json-jsonpath/) in order to specify the location of the data (within the `context` object) that will be passed as arguments to the predicate; In this case, `PREDICATE.EQUAL`, which as the name implies, is a predicate for equality check.\\n\\nIf you re-read the code, you will see that the `authorizationMiddleware` passes a `context` object to the access control library that includes the `request` and `user` objects. That\'s how they are available for access with the JSON path syntax. As for the `$.resource` in the `args`, it\'s just a key name I choose to attach the data returned from the `pipItemLoader` and automatically attached to the `context` (this happens inside our imaginary custom PIP library). That means, that the `resource` represents an `item` object with a field named `userId` which we can now access with JSON path syntax.\\n\\nLike I have already mentioned, the above is one way to do it, and it works well. You could go with something that is more general-purpose and advanced like a policy engine (e.g [OPA](https://www.openpolicyagent.org/)) but I assure you that they are definitely not a free meal either, nor without limitations. Once again, it comes down to the details of your own system and what you are trying to achieve.\\n\\n*(UPDATE 23/05/2022): [Cerbos](https://github.com/cerbos/cerbos) recently came to my attention which follows this \\"contextual\\" approach I am describing above. Maybe you can check it out as well!*\\n\\n### Potential problems\\n\\nI would like to briefly mention a few situations that you might come up against as a heads up and what you can try to do in order to solve them.\\n\\n##### Bulk enforcement\\n\\nThis becomes apparent as soon as you have some kind of listing endpoint. How will you check if the user is authorized to access all the items in the result? Checking them one by one is probably the first thing that comes to mind, but that means you will have to load them first, plus, it might be slow if you need to keep loading 1000 items on every request even for users that are not allowed to access that data.\\n\\nIn our implementation above this is solved with our routes map and the `condition` key. When you are listing items, you are probably passing some kind of filters to the endpoint via query parameters, which means you can easily use those filters and decide what to do before you even load the data. For roles that are allowed to pass whatever filters they want (e.g. an admin role), you can just omit the `condition` key.\\n\\nThe important thing here is that the authorization mechanism is not getting coupled with internal details of how you actually implement your data filtering. It just stays on a very shallow layer of your service which is publicly available to use.\\n\\n##### Not Found requests in PIP loaders\\n\\nThis is something that I am still working on myself. I have tried various approaches but I am not 100% satisfied with any of them.\\n\\nLet\'s asume that you have your `pipItemLoader` in which you load an item with id X. What should happen if the item does not exist? Should we return an authorization error? Should we return an `ItemNotFound` error? If we do the first one, isn\'t it misleading for the API caller? Especially if the user actually has access to load items. If we do the second one, before we check if the user is authorized for this action, wouldn\'t it be bad from a security perspective to provide such info? Maybe we should return a special value from the loader and if it\'s detected to let the request go through, and HOPEFULLY, our controller will be doing checks if the item exists or not.\\n\\nYou can try any of the above and something might fit your needs, or you can be creative and let me know if you find something interesting as well!\\n\\n##### Duplicate database round trips\\n\\nAs you might have noticed on our implementation above for the `GET` endpoint, is that we are loading the same item twice; once in the `pipItemLoader` and once in `getItemHandler`. Why hit the database twice when you can just avoid it?\\n\\nOne solution is to cache the data in order for the second call to return the cached data. But why hit the cache when you can avoid that as well? How? Just use a data loader and persist the data in RAM (and cache them as a side effect) for as long as the request lives and clear them upon finish with a middleware. For example, for `Node.js` you could use the [dataloader](https://www.npmjs.com/package/dataloader) package. I am pretty sure there are similar solutions in whatever you might be using.\\n\\nOf course, none of this is necessary and might be too much. Once again, it depends on how everything is implemented on your side and more importantly, your incoming traffic load.\\n\\n##### Restricting resource fields\\n\\nDepending on user access level, return resources with specific fields removed. Some authorization libraries that I have seen provide a way to do this by exposing a function/method, but in my opinion this does not really belong there. I feel like this is a job for an authorization middleware, or at least something other than the library itself which should be kept as tight as possible.\\n\\nIf you are using the routes map approach above, then you can easily extend it to support this by adding an extra key that describes the fields that are allowed and let the middleware remove the rest.\\n\\n## Conclusion\\n\\nAs you saw, implementing authorization is hard, but it\'s also a very interesting challenge.\\n\\nAlthough there is a popular belief that in a monolith is easier to implement authorization, in my opinion both the monolith and a microservices architecture have a lot in common when it comes to the authorization mechanism when that same mechanism has access to the application data it needs. The main difference is, as long as that mechanism no longer has a straight forward way to get that data, things start to get more complicated. Due to the independent nature of microservices, this can be easily observed, but the same complexity can be also observed within the same organization if multiple monoliths need to have a common authorization system.\\n\\nI am definitely not done with looking for better solutions than the ones I have already suggested and I am looking forward to hearing what others are doing.\\n\\nThe good thing is, that more and more people are starting to take this more seriously and spend more time on it. Hopefully, at some point we will solve it more elegantly and have a more unified approach. Until then, good luck!\\n\\n**PS:** I know you are going to ask me, so I am telling you right now that I made all the diagrams with [draw.io](https://drawio-app.com/)."},{"id":"my-2021-reads","metadata":{"permalink":"/my-2021-reads","source":"@site/blog/my-2021-reads.md","title":"My 2021 reads","description":"On A Life Well Spent: Cicero\'s De Senectute","date":"2021-12-25T00:00:00.000Z","tags":[{"inline":true,"label":"books","permalink":"/tags/books"}],"readingTime":0.85,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"my-2021-reads","title":"My 2021 reads","date":"2021-12-25T00:00:00.000Z","authos":"alolis","tags":["books"]},"unlisted":false,"prevItem":{"title":"Authorization in a microservices world","permalink":"/authorization-in-a-microservices-world"},"nextItem":{"title":"Node.js fork is slow; Deal with it","permalink":"/node-js-fork-is-slow-deal-with-it"}},"content":"[![On A Life Well Spent: Cicero\'s De Senectute](./assets/book_covers/on_a_life_well_spent_marcus_tullius_cicero.jpg)](https://www.goodreads.com/book/show/51881206-on-a-life-well-spent)\\n[![Principles: Life and Work](./assets/book_covers/principles_ray_dalio.jpg)](https://www.goodreads.com/book/show/34536488-principles)\\n[![Algorithms to Live By: The Computer Science of Human Decisions](./assets/book_covers/algorithms_to_live_by_brian_christian.jpg)](https://www.goodreads.com/book/show/25666050-algorithms-to-live-by)\\n[![The Five Dysfunctions of a Team: A Leadership Fable](./assets/book_covers/the_five_dysfunctions_of_a_team_patrick_leoncini.jpg)](https://www.goodreads.com/book/show/21343.The_Five_Dysfunctions_of_a_Team)\\n[![Chicken Soup for the Soul](./assets/book_covers/chicken_soup_for_the_soul_jack_canfield.jpg)](https://www.goodreads.com/book/show/801178.Chicken_Soup_for_the_Soul)\\n[![Made to Stick: Why Some Ideas Survive and Others Die](./assets/book_covers/made_to_stick_chip_heath.jpg)](https://www.goodreads.com/book/show/69242.Made_to_Stick)\\n[![No Rules Rules: Netflix and the Culture of Reinvention](./assets/book_covers/no_rules_rules_reed_hastings.jpg)](https://www.goodreads.com/book/show/49099937-no-rules-rules)\\n[![Digital ZettelKasten](./assets/book_covers/digital_zettelkasten_david_kadavy.jpg)](https://www.goodreads.com/book/show/58165477-digital-zettelkasten)\\n[![How to take smart notes](./assets/book_covers/how_to_take_smart_notes_sonke_ahrens.jpg)](https://www.goodreads.com/book/show/34507927-how-to-take-smart-notes)\\n[![Beginning Neo4j](./assets/book_covers/beginning_neo4j_chris_kemper.jpg)](https://www.goodreads.com/book/show/28388921-beginning-neo4j)"},{"id":"node-js-fork-is-slow-deal-with-it","metadata":{"permalink":"/node-js-fork-is-slow-deal-with-it","source":"@site/blog/node-js-fork-is-slow-deal-with-it.md","title":"Node.js fork is slow; Deal with it","description":"Dealing with Node.js fork slowness","date":"2021-09-27T00:00:00.000Z","tags":[{"inline":true,"label":"development","permalink":"/tags/development"},{"inline":true,"label":"battlefield","permalink":"/tags/battlefield"},{"inline":true,"label":"nodejs","permalink":"/tags/nodejs"},{"inline":true,"label":"javascript","permalink":"/tags/javascript"},{"inline":true,"label":"no_silver_bullet","permalink":"/tags/no-silver-bullet"}],"readingTime":4.68,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","title":"Software Engineer","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":"alolis","page":null}],"frontMatter":{"slug":"node-js-fork-is-slow-deal-with-it","title":"Node.js fork is slow; Deal with it","date":"2021-09-27T00:00:00.000Z","description":"Dealing with Node.js fork slowness","authors":"alolis","tags":["development","battlefield","nodejs","javascript","no_silver_bullet"]},"unlisted":false,"prevItem":{"title":"My 2021 reads","permalink":"/my-2021-reads"},"nextItem":{"title":"Riding the bull; the npm package, that is","permalink":"/riding-the-bull"}},"content":"Yes. I know. Forking a process in `Node.js` is slow. Instead of crying about it, let\'s see how we can handle it!\\n\\nLet\'s assume that you have a service in which you:\\n\\n1. Accept a request\\n2. Fork a process with [`child_process.fork`](https://nodejs.org/api/child_process.html#child_process_child_process_fork_modulepath_args_options)\\n3. Execute some code within that process\\n4. Exit from the child process\\n5. Complete the request\\n\\nProbably the first thing you tried was to receive the request, spin up a process, do whatever you need in the processor, and exit. You timed the whole thing and your jaw dropped that it took a million years for the request to complete, even if you are just doing a `console.log(\'I love kittens\')` inside your processor. \\n\\nDon\'t bother. I will tell you right now that the bottleneck is the forking.\\n\\n\x3c!--truncate--\x3e\\n\\n> \\"**OUTRAGEOUS!** I should have used *[INSERT_OTHER_TECH_HERE]* which is super awesomely fast and all the cool kids are using it! Some random dude on medium.com says it is true!\\n> \\n> *-- your loud voice*\\n\\nWell, instead of re-writting the whole thing in a different language, I have an alternative for you; **use a pool of forked child processes.\\n**\\n\\n## Approach\\n\\nThe idea is straightforward; Upon service initialization, fork a bunch of processes, and whenever a request comes in, get a resource (a child process) from the pool and use `IPC` communication to send commands to it. After the processor completes, return it to the pool. \\n\\nThe first thing for all this of course, is a pool. The good news is that there is no need to implement your own, you can just use this lovely `npm` package, [generic-pool](https://www.npmjs.com/package/generic-pool), or the native [cluster](https://nodejs.org/api/cluster.html) module depending on your use case.\\n\\nFor this post, I will use `generic-pool` so lets start with the processors pool which will look something like this:\\n\\n```javascript title=\\"pool.js\\"\\nimport {fork} from \'child_process\';\\nimport GenericPool from \'generic-pool\';\\nimport logger from \'/your/logger\';\\n\\nconst commandProcessorsPool = GenericPool.createPool({\\n  create: () => {\\n    const modulePath = path.join(__dirname, \'processor.js\');\\n    const commandProcessor = fork(modulePath);\\n\\n    logger.debug(`Forked command processor with pid ${commandProcessor.pid}`);\\n\\n    return commandProcessor;\\n  },\\n  destroy: (commandProcessor) => {\\n    logger.debug(`Destroying command processor with pid ${commandProcessor.pid}`);\\n\\n    commandProcessor.removeAllListeners();\\n    commandProcessor.kill(\'SIGKILL\');\\n  },\\n  validate: commandProcessor => commandProcessor.connected && !commandProcessor.killed\\n}, {\\n  testOnBorrow: true,\\n  min: 2, // Depending on your load, set a MINIMUM number of processes that should always be available in the pool\\n  max: 5 // Depending on your load, set a MAXIMUM number of processes that should always be available in the pool\\n});\\n\\ncommandProcessorsPool.on(\'factoryCreateError\', logger.debug);\\ncommandProcessorsPool.on(\'factoryDestroyError\', logger.debug);\\n```\\n\\nAnd of course, you will also need to implement the actual processor which looks like this:\\n\\n```javascript title=\\"processor.js\\"\\nimport {serializeError} from \'serialize-error\';\\nimport logger from \'/your/logger\';\\nimport {MESSAGE_STATUS} from \'./pool.js\';\\n\\nprocess.on(\'message\', async (message) => {\\n  try {\\n    // Read and validate input data from `message` and do whatever you need to do...\\n    const {name} = message;\\n    const result = await petKitten(name);\\n    \\n    // All went well, send the result of your function to the parent process...\\n    process.send({status: MESSAGE_STATUS.OK, data: result});\\n  } catch (e) {\\n    logger.debug(e);\\n\\n    /* \\n      In the real world, your processor will probably need to handle errors as well and pass those errors to\\n      the parent process. Unfortunately, sending `Error` instances via `IPC` is not possible, BUT, we can just\\n      serialize them and then deserialize them on the parent process!\\n    */\\n    process.send({status: MESSAGE_STATUS.ERROR, data: serializeError(e)});\\n  }\\n};\\n```\\n\\nGoing back to our pool implementation, the only thing left now is the function that will be executing our commands:\\n\\n```javascript title=\\"pool.js\\"\\n// ... omitted previous code for succinctness\\n\\nimport {deserializeError} from \'serialize-error\';\\n\\nconst MESSAGE_STATUS = {\\n  OK: \'ok\',\\n  ERROR: \'error\',\\n};\\n  \\nasync function executeCommand(params) {\\n  const commandProcessor = await commandProcessorsPool.acquire();\\n  \\n  try {\\n    const commandProcessorTask = () => {\\n      return new Promise((resolve, reject) => {\\n        // https://nodejs.org/api/child_process.html#child_process_event_error\\n        commandProcessor.on(\'error\', reject);\\n\\n        commandProcessor.on(\'message\', (message) => {\\n          const {status, data} = message;\\n\\n          const handlersMap = {\\n            [MESSAGE_STATUS.OK]: () => resolve(data),\\n            \\n            // Don\'t forget to deserialize the error first!\\n            [MESSAGE_STATUS.ERROR]: () => reject(deserializeProcessorError(data)           \\n          };\\n\\n          const handler = handlersMap[status];\\n\\n          if (!handler) {\\n            return reject(new Error(`Unknown command processor message status \'${status}\'`));\\n          }\\n\\n          handler();\\n        });\\n\\n        commandProcessor.send(params);\\n      });\\n    };\\n    \\n    const result = await commandProcessorTask();\\n    \\n    return result;\\n  } finally {\\n    // Make sure that the command processor is returned to the pool no matter what happened\\n    await commandProcessorsPool.release(commandProcessor);\\n  }\\n}\\n\\nexport {\\n  MESSAGE_STATUS,\\n  executeCommand\\n}\\n```\\n\\nFor the shake of this example, I am going to assume that you are using `express.js`. The following is a very simple and short snippet on how to bring everything together, and execute a command when a request is received:\\n\\n```javascript title=\\"express.js\\"\\nimport express from \'express\';\\nimport {executeCommand} from \'./pool.js\'; // By importing the file, our pool will be initialized\\nimport logger \'/your/logger\';\\n\\nconst app = express();\\n\\napp.post(\'/pet_kitten\', (req, res) => {\\n  const {name} = req.body;\\n  \\n  // If this is a long-running process, then we shouldn\'t really block the request by using await.\\n  // Depending on your case here, you might want to handle the actual command execution differently.\\n  executeCommand({name}).catch(logger.error);\\n\\n  res.status(202); // HTTP Status Accepted\\n  res.json({message: `Petting ${name} is underway...`});\\n\\napp.listen(3000, () => {\\n  logger.info(`kitten app listening at http://localhost:${port}`)\\n})\\n```\\n\\n## Conclusion\\n\\nAlthough the above was a simple real world example on how to use a pool of processes, it can be the basis for more advanced usage. For example each processor can be modified to accept various commands instead of being limited to just one function. You could also add an `onMessage` event handler to support commands that send updates while they are being executed. I will leave those for another blog post! \\n\\nDepending on your use case though, you can do a lot of different things by expanding the approach I have just described. \\n\\n**The important thing here is to remember that most of the time, the problem is not the tool, it\'s your attitude towards the tool. Be creative and solve shit.**"},{"id":"riding-the-bull","metadata":{"permalink":"/riding-the-bull","source":"@site/blog/riding-the-bull.md","title":"Riding the bull; the npm package, that is","description":"This is a post about a specific Node.js library, named bull, which is used to execute background jobs.","date":"2021-08-16T00:00:00.000Z","tags":[{"inline":true,"label":"development","permalink":"/tags/development"},{"inline":true,"label":"battlefield","permalink":"/tags/battlefield"},{"inline":true,"label":"nodejs","permalink":"/tags/nodejs"},{"inline":true,"label":"javascript","permalink":"/tags/javascript"}],"readingTime":21.43,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":null,"page":null}],"frontMatter":{"slug":"riding-the-bull","title":"Riding the bull; the npm package, that is","date":"2021-08-16T00:00:00.000Z","author":"Alexander Lolis","author_url":"https://github.com/alolis","author_image_url":"https://avatars.githubusercontent.com/u/82233?v=4","tags":["development","battlefield","nodejs","javascript"]},"unlisted":false,"prevItem":{"title":"Node.js fork is slow; Deal with it","permalink":"/node-js-fork-is-slow-deal-with-it"},"nextItem":{"title":"How to pass the first round of my interviews","permalink":"/how-to-pass-the-first-round-of-my-interviews"}},"content":"This is a post about a specific `Node.js` library, named [bull](https://github.com/OptimalBits/bull), which is used to execute background jobs. \\n\\nThe reason I am writing this is to address some cases which the library does not cover out of the box and share our experience on how we solved them in case others have the same needs.\\n\\n\x3c!--truncate--\x3e\\n\\nI assume that you are already familiar with `bull` and how to use it so I will not waste time providing instructions. The official documentation can be found [here](https://github.com/OptimalBits/bull#documentation), so I strongly recommend looking at it first before you read any further.\\n\\n## Background\\n\\nIn a system we were working on, we had the requirement for a jobs service. That jobs service had to be written in `Node.js` for reasons that are irrelevant to this article. The important part is that the users of the system would be able to submit jobs of different types (copies, moves, compressing/extracting files, etc) to the service via a UI and then track their progress and manage them.\\n\\nEven though `bull` looked promising, with a nice set of features out of the box, we still had to solve a few problems on our own. **After using this library for some time now with success**, and seeing that others have similar requirements, I thought I should share our experiences in case someone finds them useful.\\n\\nWe were trying to avoid using an external database and keeping in sync the jobs with `bull` since we didn\'t need any advanced querying, plus, it is always a pain point to keep two different sources in sync. **One source of truth is always easier...unless the code complexity increases a lot (without even providing a competitive advantage) and suddenly the problems that come with syncing do not sound that bad...**\\n\\nAlthough we did have a few interesting iterations and used them in production for some time, we ended up going with a database after all.\\n\\n:::caution\\nif you have been using [my fork](https://github.com/alolis/bull/tree/rapiddot2) then please stop doing so. All necessary changes are now in the official `bull` repository.\\n:::\\n\\n## Fetching jobs by user id\\n\\n#### Approach #1 - Using the `bull` API\\n\\nThe first pain point in our quest for a database-less solution, was, that the `bull` API does not expose a method that you can fetch all jobs by filtering the job data (in which the `userId` is kept). Even if it did, it would probably be expensive to fetch the data by going through all the Redis `HSET` structures that the library uses. \\n\\nYour only **API-based option** here is to fetch ALL the jobs with `Queue.getJobs` and do the filtering on the application level. This, of course, is not optimal at all, unless you know that your dataset will always be small. Not our case unfortunately but it might be OK for yours.\\n\\n#### Approach #2 - Using a Redis secondary index\\n\\nAnother approach, since you will already have Redis deployed, is to **[use a Redis secondary index](how-to-tag-data-in-redis.md#using-sets-as-secondary-indexes)**. The general idea is to store a Redis `LIST` with all the job ids associated with a user id as the key. Then, you would load that list, loop it, and fetch each job with `Queue.getJob`. \\n\\nOnce again, nothing is for free. You would need to add logic to maintain those lists, cleanup scripts to ensure that nothing in those lists is dead, etc. Depending on your load, this might have a performance penalty since fetching multiple jobs with one call is not available in the `bull` API, but, if you are not overdoing it I think you will be fine.\\n\\n#### Approach #3 - One queue per user\\n\\nAnother, more complex approach, if you do not want to use a database, is to **use one queue per user** in combination with [connections re-use](https://github.com/OptimalBits/bull/blob/develop/PATTERNS.md#reusing-redis-connections). Depending on your use case and your user base, this might be just fine for you. You would still need to have all the queue objects loaded in memory at the same time, route each user request to the appropriate queue (e.g. by maintaining a `Map` with `userId->Queue` association), load all existing queues upon service initialization (and since there is no `Queue.list` method you need to [scan Redis manually to get the queue names](https://github.com/OptimalBits/bull/issues/1024#issuecomment-414478540), and then instantiate the queues), cleanup, etc. If your load is relatively small, with a couple of thousand users, you will probably be ok with this. \\n\\nIf you need to have multiple queues per user, then I am telling you already that this will be far more complex than you think and you should probably avoid it. **We have already done that, it worked, but, we weren\'t very happy with it, it does not scale well, and it will not work in a distributed environment.** \\n\\nIf you really want to give it a go, however, the following example code should give you the general idea.\\n\\n#### The `UserQueue` class\\n\\n```javascript\\nimport Queue from \'bull\';\\nimport _ from \'lodash;\\n\\n// Keep track of all our user queues\\nconst userQueues = new Map();\\n\\n// The `UserQueue` class can serve as a layer between `bull` and your application if you need\\n// multiple queues per user and implement any method that you need here in order to manage\\n// the underlying queues.\\nclass UserQueue {\\n  constructor(userId) {\\n    this.queues = new Map();\\n  }\\n  \\n  initQueues() {\\n    // Initialize all your queues and for each queue add an entry to the this.queues\\n    // map with the queue type as a key and the Queue object as value. Each queue needs\\n    // to include the userId in it\'s name along with the queue type in order to be easily\\n    // identifiable e.g. somePrefix:45:copies\\n    \\n    // Make sure that you re-use Redis connections here or else you will end up with A LOT\\n    // of open connections since each queue requires at least 3.\\n  }\\n  \\n  async getJobs() {\\n    // You basically need to loop all queues and get the jobs from each queue. No need from filtering\\n    // on the application level since all the jobs belong to this user. This is a very simple example\\n    // however, check Queue.getJobs documentation since you might need to pass extra parameters.\\n    const promises = _.map(this.queues, queue => queue.getJobs());\\n    const jobs = await Promise.all(promises);\\n    \\n    return jobs;\\n  }\\n  \\n  // Add any other methods you might need to interact with the underlying queues\\n}\\n\\n// Check if the queue is already in our Map or else instantiate it and add it before returning it\\nfunction loadUserQueue(userId) {\\n  if (userQueues.has(userId) {\\n    return userQueues.get(userId);\\n  } else {\\n    const userQueue = new UserQueue(userId);\\n    userQueues.set(userId, userQueue);\\n    \\n    return userQueue;\\n  }\\n}\\n\\n/* \\n   Upon service initialization\\n*/\\n\\n// Load all queue key names and extract the user id from the key matches\\nconst userIds = await getUserIdsFromQueueKeys();\\n\\n// Instantiate all queues in order to start processing jobs\\n_.forEach(userIds, loadUserQueue);\\n\\n/* \\n   During normal operation\\n*/\\n\\n// A request comes in to fetch the jobs for user 45\\nconst userQueue = loadUserQueue(45);\\n\\nconst jobs = await userQueue.getJobs();\\n\\n```\\n\\n#### Approach #4 - Using a database\\n\\nIf you want to use a database, you need to built a layer in front of `bull` to bridge them together and control the flow. That layer, can be a service class, or separate functions, or whatever fits your codebase best. \\n\\nOf course, there is the issue of data synchronization. If, for example, you have some kind of cleanup script that runs `Queue.clean` every now and then, you need to remove the jobs from your database as well. That\'s where the [queue event handlers](https://github.com/OptimalBits/bull/blob/develop/REFERENCE.md#events) come in handy!\\n\\n#### The `JobService` class\\n\\nSo, an approach with a service class would look like this:\\n\\n```javascript\\nimport Queue from \'bull\';\\n\\nclass JobService {\\n  constuctor() {\\n    this.queues = new Map();\\n    \\n    this.initQueues();\\n  }\\n  \\n  /**\\n    Initialize all service queues.\\n    \\n    @private\\n  */\\n  initQueues() {\\n    // Initialize all your queues and update `this.queues`\\n    \\n    // For each queue run `this.attachQueueHandlers(queue)`\\n  }\\n  \\n  /**\\n    Attach event handlers to each queue.\\n    \\n    @private\\n  */\\n  attachQueueHandlers(queue) {\\n     queue.on(\'removed\', (job) => {\\n       // Remove from your database\\n    });\\n  }\\n  \\n  async add(jobData) {\\n    // Add the job to your database\\n    \\n    // Add the job to the appropriate queue but remember to use the id from database by passing\\n    // it to the `Queue.add` method!\\n    \\n    return job;\\n  }\\n  \\n  async find(filters = {}) {\\n    // Use your database to find the jobs you want\\n  }\\n  \\n  // Add any other methods you might need to manage your jobs\\n}\\n\\n// Global service object\\nconst jobService = new JobService();\\nconst job = await jobService.add(....);\\n\\n```\\n\\nFrom what you have probably already figured out, if you want more than just fetching the jobs of a specific user, then the place to add more code is here!\\n\\n## Removing an active job in sandboxed environments\\n\\n#### Overview\\n\\nThis was another pain point when we started using `bull`; the inability to remove - basically abort - a running job in a [sandboxed environment](https://github.com/OptimalBits/bull#separate-processes). The [first approach we tried](https://github.com/OptimalBits/bull/issues/1098), although it did work for us, it was a bad solution since our [fork](https://github.com/alolis/bull/tree/rapiddot) was straying way far out from the core boundaries of the library. That means, that after a while, maintenance starts becoming a nightmare. \\n\\nAnd of course, the nightmare became true after bluebird (which supports [promise cancellation](http://bluebirdjs.com/docs/api/cancellation.html)) was [completely removed](https://github.com/OptimalBits/bull/commit/f05e67724cc2e3845ed929e72fcf7fb6a0f92626) from the library. That would mean that our fork would not be able to be in sync with the official repo from now on. To be fair here, I think that move was 100% correct from the `bull` side and it helped us push in a far better direction. Besides, I do love a challenge!\\n\\n#### Approach\\n\\nSo, the idea is simple: \\n\\n1. Send a `kill` signal to the sandboxed job processor\\n2. Handle the signal from within the processor\\n3. Discard the job (in order for `bull` to not retry it)\\n4. `process.exit` from within the processor and let `bull` do the rest\\n\\nAs with all recipes, these are the ingredients to make it work:\\n\\n* `Job.update` to be available in the sandboxed environment ([added in v3.23.0](https://github.com/OptimalBits/bull/releases/tag/v3.23.0))\\n* `Job.discard` to be available in the sandboxed environment ([added in v3.24.0](https://github.com/OptimalBits/bull/releases/tag/v3.27.0))\\n* A high order function to wrap all our processors with the common functionality\\n\\n#### The `wrapProcessor` function\\n\\nThe following code snippet shows a simplified version of a higher order function that can be used to wrap all your processors in order to enhance them with your functionality and keeping all that code in one place. In our own wrapper version, we do other things as well, like, processor validation, setting the state of the jobs in our database, wrapping any errors thrown, etc. Any extra functionality that you need to run before and/or after executing the processor, can be done here.\\n\\n```javascript\\nimport logger from \'/your/logger\';\\n\\n/**\\n * Wraps a processor and adds common functionality to avoid code duplication.\\n * Make sure that ALL processors are exported by being wrapped first.\\n *\\n * @param {Function} processor\\n * @throws {Error}\\n * @returns {Function}\\n */\\nfunction wrapProcessor(processor) {\\n  async function wrappedProcessor(job) {\\n     const exitHandler = (exitCode) => {\\n      logger.debug(`Received SIGTERM for job id \'${job.id}\' with exit code \'${exitCode}\' and PID \'${process.pid}\'`);\\n\\n      // Discard the job first to ensure that it will not be retried after a process kill.\\n      job.discard();\\n     \\n      process.exit(exitCode);\\n    };\\n\\n    process.on(\'SIGTERM\', exitHandler);\\n\\n    try {\\n      // Store the process pid in order to be able to abort the process at any time by simply killing it.\\n      await job.update({...job.data, pid: process.pid});\\n\\n      const result = await processor(job);\\n\\n      return result;\\n    } finally {\\n      // Bull internally uses a child pool of forked processors that are being re-used so we need to make sure\\n      // that we remove the listener before the processor returns to the pool or else we will cause memory leakage.\\n      process.removeListener(\'SIGTERM\', exitHandler);\\n    }\\n  }\\n\\n  return wrappedProcessor;\\n}\\n\\n```\\n\\n#### Usage\\n\\n```javascript\\n// myProcessor.js\\nimport wrapProcessor from \'/some/path/wrap_processor.js\'\\n\\nasync function myProcessor(job) {\\n   // Your processor code here\\n   \\n   return result;\\n}\\n\\n// Wrap your processor!\\nexport default wrapProcessor(myProcessor);\\n\\n// main.js\\nimport Queue from \'bull\';\\nimport kill from \'tree-kill\';\\n\\nfunction killJob(queue, jobId) {\\n  return new Promise((resolve, reject) => {\\n    try {\\n      const job = await queue.getJob(jobId);\\n      \\n      if (!job) {\\n        return resolve(false);\\n      }\\n      \\n      // You can also add an extra check here if the PID does not exist\\n      // and return resolve(false) if it\'s true.\\n      \\n      kill(job.data.pid, \'SIGTERM\', (err) => {\\n        if (err) {\\n          reject(err);\\n        } else {\\n          resolve(true);\\n        }\\n      });\\n \\t} catch (e) {\\n \\t  reject(e);\\n \\t}\\n });\\n}\\n\\nconst queue = new Queue(\'downloader\');\\nqueue.process(\'/some/path/processors/my_processor.js\'\')\\nconst job = await queue.addJob({url: \'https://example.com/file1.mov\'});\\n\\n// The following will send a SIGTERM to the underlying job process, and if it\'s still active, the\\n// job processor will receive it, exit itself, and the job will be moved to the failed queue by bull.\\nawait killJob(queue, job.id); \\n\\n```\\n\\nAnd of course, you can always update the [`JobService`](riding-the-bull.md#the-jobservice-class) class and implement an `abort` method like so:\\n\\n```javascript\\nclass JobService {\\n  // ... omitted previous code for succinctness\\n  \\n  async load(id) {\\n    // Load from database\\n    \\n    // If id does not exist, throw error\\n    \\n    return job;\\n  }\\n  \\n  async abort(id) {\\n    const job = await this.load(id);\\n    \\n    await this.kill(job.data.pid);\\n    \\n    return job;\\n  }\\n  \\n  kill(pid) {\\n    // Kill code here\\n  }\\n}\\n```\\n\\n\\n## Attaching current state to jobs\\n\\n#### Overview\\n\\nThe only way to get the job state with the `bull` API at the moment is `Job.getState`. That means, that first, you need to load the job(s) and then call the method. Not very convenient I am afraid, but again, for performance reasons from the `bull` side, this is how it is. \\n\\n#### Approach #1 - Dynamically attach a `state` field to jobs\\n\\nAlthough this is not very robust since it can break after a `bull` upgrade, it worked fine for us at the beginning (before we ended up using a database) and it might do the trick for you as well. The following function can be used to attach a `state` field on each `Job` object, which is way faster than calling `.getState` for every each one of them:\\n\\n```javascript\\nimport _ from \'lodash\';\\n\\n/**\\n * Enum for possible job states.\\n *\\n * @readonly\\n * @enum {String}\\n */\\n const JOB_STATE = {\\n   ACTIVE: \'active\',\\n   WAITING: \'waiting\',\\n   DELAYED: \'delayed\',\\n   COMPLETED: \'completed\',\\n   FAILED: \'failed\',\\n   PAUSED: \'paused\',\\n   STUCK: \'stuck\',\\n   UNKNOWN: \'unknown\'\\n };\\n\\n/**\\n * The function will use some of the job fields in order to calculate the current state.\\n *\\n * @param {Job} job - The job object.\\n * @see {@link https://github.com/OptimalBits/bull/issues/1076}\\n */\\n attachStateField(job) {\\n   const {\\n     processedOn = null,\\n     delay = 0,\\n     finishedOn = null,\\n     failedReason = null\\n   } = job;\\n\\n   const statesPredicateMapping = {\\n     [JOB_STATE.COMPLETED]: () => _.isInteger(finishedOn) && _.isNull(failedReason),\\n     [JOB_STATE.ACTIVE]: () => _.isInteger(processedOn) && _.isNull(finishedOn) && _.isNull(failedReason),\\n     [JOB_STATE.DELAYED]: () => _.isNull(processedOn) && delay > 0,\\n     [JOB_STATE.WAITING]: () => _.isNull(processedOn) && delay === 0,\\n     [JOB_STATE.FAILED]: () => _.isString(failedReason)\\n    };\\n\\n   job.state = _.findKey(statesPredicateMapping, predicate => predicate()) || JOB_STATE.UNKNOWN;\\n\\n   return job;\\n}\\n\\n// Usage\\nconst queue = new Queue(\'downloader\');\\nconst jobs = await queue.getJobs();\\n_.forEach(job, attachStateField);\\n```\\n\\nYou can also check [this](https://github.com/OptimalBits/bull/issues/1076) discussion thread which includes the above plus a few more ideas in case you want to persue this any further.\\n\\n#### Approach #2 - Using a database\\n\\nIf you are using a database, then this is pretty straightforward. You add the job in the database with a default value, like `JOB_STATE.PENDING`, and then with the use of the [queue events](https://github.com/OptimalBits/bull/blob/develop/REFERENCE.md#events), we can update the job state. \\n\\nThe following is using the [`JobService`](riding-the-bull#the-jobservice-class) from our previous section to show you an example of how to do it:\\n\\n```javascript\\nclass JobService {\\n  // ... omitted previous code for succinctness\\n  \\n  /**\\n    Attach event handlers to each queue.\\n    \\n    @private\\n  */\\n  attachQueueHandlers(queue) {\\n    // Attach on queue all events that can change state like so:\\n     queue.on(\'active\', (job) => {\\n       // Update `state` field in database\\n    });\\n    \\n    // Add all the necessary queue event handlers that change state\\n  }\\n}\\n```\\n\\n## Using a custom Error object\\n\\nAnother problem that we had to solve was the need to expose custom error objects from within the processors in order to be able to pass them higher in the call chain and handle them accordingly. \\n\\nUnfortunately, `bull` does not have some kind of mechanism at the moment to do that and the only thing you have access to when an error occurs, is the `job.failedReason` which is a string. So, why not use that to our benefit?\\n\\n#### Approach\\n\\nYou basically need to create a small mechanism to `JSON.stringify` the error object you want to store and `JSON.parse` it before consumption. \\n\\nOne way to do this is by taking advantage of our previously mentioned higher order function, [`wrapProcessor`](riding-the-bull.md#the-wrapprocessor-function) in combination with a custom `Error` object that will use the `message` property of the `Error` to store a JSON stringified value. The reason we will use the `message` property is because that\'s what `bull` [uses to automatically store the failed reason](https://github.com/OptimalBits/bull/blob/v3.28.1/lib/job.js#L276).\\n\\nAfter you wrap the error thrown by the processor, you can just re-throw it and parse it in your `failed` queue event handler or when you load a job with the `Queue` class. In the following code I will use our [`JobService`](riding-the-bull#the-jobservice-class) class as an example for parsing and handling the error:\\n\\n```javascript\\n// The custom error object\\nimport ExtendableError from \'es6-error\';\\n\\nclass JobError extends ExterndableError {\\n  constructor(code, message) {\\n    this.errorObject = {\\n      code,\\n      message\\n    };\\n    \\n    super(JSON.stringify(this.errorObject));\\n  }\\n  \\n  getErrorObject() {\\n    return this.errorObject;\\n  }\\n}\\n\\n// The updated wrapProcessor function\\nimport logger from \'/your/logger\';\\n\\nfunction wrapProcessor(processor) {\\n  async function wrappedProcessor(job) {\\n    // ... omitted previous code for succinctness\\n\\n    try {\\n     // ... omitted previous code for succinctness\\n     \\n      const result = await processor(job);\\n\\n      return result;\\n    } catch (e) {\\n      logger.error(e);\\n      \\n      if (e instanceof JobError) {\\n        throw e;\\n      } else {\\n        /* \\n          Wrap the error as `JobError` and throw it. You can also create a mapping of \\"known\\" errors and assign them\\n          a specific code and error message. For example if you are doing validation within your processor, you could\\n          handle the validation error here and then wrap it as a `JobError`.\\n        */\\n      }\\n    } finally {\\n      // ... omitted previous code for succinctness\\n    }\\n  }\\n\\n  return wrappedProcessor;\\n}\\n\\n// myProcessor.js\\nasync function myProcessor(job) {\\n   // Your processor code here\\n   \\n   // Something bad happened, throw error!\\n   throw new JobError(\'myErrorCode\', \'Something very bad happened!\');\\n   \\n   return result;\\n}\\n\\n// Wrap your processor!\\nexport default wrapProcessor(myProcessor);\\n\\n// The updated `JobService` \\nimport _ from \'lodash\';\\n\\nclass JobService {\\n  // ... omitted previous code for succinctness\\n  \\n  /**\\n    Attach event handlers to each queue.\\n    \\n    @private\\n  */\\n  attachQueueHandlers(queue) {\\n    // Attach on queue all events that can change state like so:\\n     queue.on(\'failed\', (job) => {\\n       const errorObject = this.parseFailedReason(job.failedReason);\\n       \\n       // Do whatever you want with `errorObject`\\n    });\\n    \\n    // Add all the necessary queue event handlers that change state\\n  }\\n  \\n  /**\\n   * Parses failed reason which occurs when the job process gets killed or an error is thrown from within\\n   * the processor. Bull uses the `message` property from any errors inherited from `Error`, so, if that\'s the case \\n   * we should be able to get a JSON object since we stringified our error object, or else we will just handle \\n   * the `failedReason` parameter as a plain string.\\n   *\\n   * @private\\n   * @see {@link https://github.com/OptimalBits/bull/blob/v3.28.1/lib/job.js#L276}\\n   * @param {String} failedReason\\n   * @returns {Object}\\n  */\\n  function parseFailedReason(failedReason) {\\n    // https://github.com/OptimalBits/bull/blob/develop/lib/process/sandbox.js#L42\\n    const unexpectedExitString = \'Unexpected exit code\';\\n\\n    try {\\n      return JSON.parse(failedReason);\\n    } catch (e) {\\n      // If we are here, then it means that something out of our control happened\\n      // and the processor never returned a json result string as we expected.\\n      return {\\n        code: _.startsWith(failedReason, unexpectedExitString) ?\\n          \'UNEXPECTED_EXIT_ERROR\':\\n          \'INTERNAL_ERROR\',\\n         message: failedReason\\n      };\\n    }\\n  }\\n}\\n```\\n\\n## Per-user, per queue concurrency granularity \\n\\n#### Overview\\n\\nThe final and toughest pain point was that the concurrency of the [named processors](https://github.com/OptimalBits/bull/blob/develop/REFERENCE.md#queueprocess) was not working as we thought it would. \\n\\nFor our case, we needed to have a concurrency limit *per-user, per queue*, and at first, the named processors in combination with the `concurrency` option seemed that it might do the trick. Unfortunately, [that was not the case](https://github.com/OptimalBits/bull/issues/1113). The plan was to use one named processor per user to apply those limits. Not sure if that would have worked well  anyway, but it wasn\'t a viable option so we didn\'t pursue it any further.\\n\\nThe following from the `bull` documentation explains the named processors\' concurrency limitation:\\n\\n```javascript\\n/***\\n * For each named processor, concurrency stacks up, so any of these three process functions\\n * can run with a concurrency of 125. To avoid this behaviour you need to create an own queue\\n * for each process function.\\n */\\nconst loadBalancerQueue = new Queue(\'loadbalancer\');\\nloadBalancerQueue.process(\'requestProfile\', 100, requestProfile);\\nloadBalancerQueue.process(\'sendEmail\', 25, sendEmail);\\nloadBalancerQueue.process(\'sendInvitation\', 0, sendInvite);\\n```\\n\\n#### Approach #1 - One queue per queue type\\n\\nIf you need a per queue concurrency, then the simplest way to do it is to use separate queues. if your environment has some kind of limitation then you can also [re-use your connections](https://github.com/OptimalBits/bull/blob/develop/PATTERNS.md#reusing-redis-connections) as I have already mentioned.\\n\\nIn combination with the [`UserQueue`](riding-the-bull.md#the-userqueue-class) class, you could also achieve a database-less solution for a per-user, per queue concurrency granularity.\\n\\n#### Approach #2 - Using a database\\n\\nLet me start by saying that for our own needs, we have a more complex implementation so I will try to simplify this as much as I can to give you a general idea of what you can try on your own.\\n\\nThe idea is this:\\n\\n1. Keep track of all jobs in a database with a `state` and a `userId` field on each entry\\n2. Every time a job is created, completed or failed, a `JobService` method (let\'s call it `addNextPendingJobs`) will take a count of currently active jobs of the user and if they have empty slots, add some more to `bull`\\n\\n**Sounds straightforward, right? Wrong.** If your service accepts parallel requests, you will need to take into account any possible race conditions each time you count the active jobs of a user and deciding whether or not you should add it to the `bull` queue. \\n\\nExample scenario:\\n\\n1. *Request A* comes in, you execute a database count\\n2. *Request B* comes in, you execute a database count\\n3. *Count B* returns, slots are available, code starts adding jobs to `bull`\\n4. Before the jobs from *Count B* have been added to bull and the `state` has been updated, *Count A *returns. Slots are available (even though they are not) and code starts adding jobs to `bull`\\n5. You now have more active jobs than your limit allows\\n\\nSo, depending on the database you are using, the atomicity level it offers, whether or not it supports transactions and exclusive locking, you will need to implement your `addNextPendingJobs` accordingly. **In other words, you need to ensure that the entries that are being read during the counting are locked like they are being updated and not allow other operations from modifying them until the transaction ends.** \\n\\nFor example, in the SQL world, this can be done with `SELECT...FOR UPDATE` but this is way out of the scope of this article. **If you have NO CLUE what I am talking about then I recommend starting reading material on locking and the documentation of your database before you try anything further.**\\n\\nIf your database does not support any of the above, or if you want to use Redis to implement the whole thing, you could also use something like [redlock](https://github.com/mike-marcacci/node-redlock) instead. \\n\\nAnd of course, **you can always process everything in sequence and avoid any possible race conditions**, but it will create a bottleneck if you have a big load. As always, depending on your case, it\'s up to you.\\n\\nFinally, you will need to use the [queue events](https://github.com/OptimalBits/bull/blob/develop/REFERENCE.md#events) to handle the `completed` and `failed` events and add more jobs whenever necessary. \\n\\nThe updated code in our [`JobService`](riding-the-bull.md#the-jobservice-class) will look like this:\\n\\n```javascript\\nimport logger from \'/your/logger\';\\n\\nclass JobService {\\n  // ... omitted previous code for succinctness\\n  \\n  /**\\n    Attach event handlers to each queue.\\n    \\n    @private\\n  */\\n  attachQueueHandlers(queue) {\\n    // Attach on queue all events that can add next pending jobs like so:\\n     queue.on(\'completed\', (job) => {\\n       // this.addNextPendingJobs\\n    });\\n    \\n    queue.on(\'failed\', (job) => {\\n      // For the failed scenario, we need to check whether or not the failed job will automatically\\n      // re-run by `bull` before we try to add more jobs\\n      if (job.isDiscarded() || job.attemptsMade >= job.opts.attempts) {\\n        // this.addNextPendingJobs\\n      }\\n    });\\n  }\\n  \\n  async create(jobData) {\\n    // ... code\\n    \\n    // Add next pending jobs whenever possible without blocking\\n    this.addNextPendingJobs(jobData.userId, jobData.type).catch(logger.error);\\n  }\\n  \\n  async addNextPendingJobs(userId, jobType) {\\n     // Start a transaction/take lock\\n     \\n     // Count all ACTIVE entries of the specified `userId` and `jobType`\\n     \\n     // If the active are less than MAX ALLOWED then update those entries to WAITING\\n     // and start adding them to the appropriate `bull` queue\\n     \\n     // Commit transaction/release lock\\n  }\\n}\\n```\\n\\nThe above is simplified but it should give you some idea on how to proceed. As a final remark, **the whole approach is not bulletproof**. You need to ensure that queue stagnation will never happen in case something goes wrong in `addNextPendingJobs` and more jobs are not added to the queue. A retry strategy can be used or maybe the code that adds more jobs can live in a `setInterval` if you are using a single service. \\n\\nLike I said plenty of times before, depends on your use case and there is always room for improvement.\\n\\n## Conclusion\\n\\nThis has been a long post but I wanted to show you that with a little creativity a lot can be accomplished. **No magic tool, or a magic library exists out there that will cover all your requirements out of the box, and being eager to jump into a custom solution from the first sign of limitation is a bad tactic**. Of course, you will need to spend some time figuring out how an existing solution works, but if its core fits your needs and you can build on top of it, then you will just need to solve a specific set of problems instead of the whole spectrum of what the existing solution is solving.\\n\\nIf you have any questions/feedback for any of the above, then do not hesitate to email me!"},{"id":"how-to-pass-the-first-round-of-my-interviews","metadata":{"permalink":"/how-to-pass-the-first-round-of-my-interviews","source":"@site/blog/how-to-pass-the-first-round-of-my-interviews.md","title":"How to pass the first round of my interviews","description":"A cheat sheet for future software developer candidates","date":"2021-01-25T00:00:00.000Z","tags":[{"inline":true,"label":"business","permalink":"/tags/business"},{"inline":true,"label":"management","permalink":"/tags/management"},{"inline":true,"label":"experiments","permalink":"/tags/experiments"},{"inline":true,"label":"interviews","permalink":"/tags/interviews"}],"readingTime":8.82,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","title":"Software Engineer","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":"alolis","page":null}],"frontMatter":{"slug":"how-to-pass-the-first-round-of-my-interviews","title":"How to pass the first round of my interviews","date":"2021-01-25T00:00:00.000Z","description":"A cheat sheet for future software developer candidates","authors":"alolis","tags":["business","management","experiments","interviews"]},"unlisted":false,"prevItem":{"title":"Riding the bull; the npm package, that is","permalink":"/riding-the-bull"},"nextItem":{"title":"My 2020 reads","permalink":"/my-2020-reads"}},"content":"If you are reading this, then congratulations, you\u2019ve just checked one of the things that I am looking for in a candidate; **the ability to do some basic research**. In this case, by simply reading information about the company you are applying to.\\n\\nI am astounded by the number of candidates that come for an interview and have no clue what the company does exactly. Except of what the \u2013 clueless recruiter \u2013 might have told them, they haven\u2019t even bothered to check the company site in detail. There is occasionally someone that has read the first paragraph of the home page, but that\u2019s usually it. **If you don\u2019t give a damn or don\u2019t even have the curiosity to check out the place you will be spending a large part of your day, then I do not want to work with you.**\\n\\nIf on the other hand you do give a damn, then keep reading.\\n\\n\x3c!--truncate--\x3e\\n\\n**Don\u2019t be late.** I hate when people are being late. I do not care about any excuses, and unless there was a real emergency, you should be on time. It\u2019s a sign of respect, professionalism and that you understand that your time is not more important than the other person\u2019s time.\\n\\nI will be polite upon your arrival. **I will offer you something to drink**, probably give you a few options but please choose the water. It\u2019s not a cafeteria and I am not your barista. I am your interviewer so do not abuse my hospitality. That means you should not ask me for a latte like someone did once. Yes, that has really happened. He wanted to look \\"cool\\" as they advised him in the computer science school he went to during his \\"how to prepare for an interview\\" course. Nope, I did not find it cool.\\n\\nWe will be moving to the meeting room where the interview will take place. **I am an easy person to talk to** so try to relax. We will start with some **casual conversation** about your past experience, things that interest you, what happened to your last job, what you expect from your new job, how you try to improve yourself every day, what was the last book you read, what hobbies you have and basically anything else that might give me the slightest clue about the person you are.\\n\\nI want to be absolutely clear about this. **What type of person you are and how well you will fit in the team is the most important thing for me**. Of course, your technical skills are important as well, but let me put it this way; if it comes down to two candidates, and the first one has an open personality and qualities that I am looking for, but the second one does not, although their technical skills are better, I will **ALWAYS** choose the first one. You can teach a skill but you cannot teach someone how to be a human being.\\n\\n**What qualities am I looking for?** Honesty, patience, someone who is observant, reliable, and respectful of those around them. I want to see a passionate, trustworthy person. A person that is not always looking for excuses or whines about everything but rises up to the occasion. And of course, to have some sense of humor, because, what is life without humor?\\n\\n**Try to be as sincere as possible** about yourself. Even if you pretend to be someone you are not during the interview, or if you manage to give the answers I want to hear, you won\u2019t be able to hide your real self after a couple of months of working closely together. **Under pressure, all characters are truly revealed. And you will be pressed. So please, if you plan to bamboozle me, do both of us a favor and walk away because I will be reluctant to work with you.\\n**\\n\\nAt some point, after I feel I have heard enough about you \u2013 or too little \u2013 **we will move to the technical part of the interview. Please do not suck. No seriously, please do not suck.** By sucking I mean that when I ask you to write a for loop (for a simple \u201cFizzBuzz\u201d test) on the whiteboard just to check that you are actually able to write ANY code at all before we proceed, please do write it without hesitation. Unfortunately, it has happened more than once people tell me \u201cI haven\u2019t written code for the last couple of months and I do not remember how to write a loop at the moment\u201d or \u201cI did not expect to write any code. Nobody asked me in the other interviews\u201d. SERIOUSLY? This is an interview for a software development position. I definitely want to see SOME code.\\n\\nYes, I know that phone screens exist, yes I know that you can give to the recruiter a cut-off test, yes I know all about the awesome ways to avoid wasting your time, but sometimes, these people just slip through and my answer to these people is, find a different work field. I know that someone told you that computer science \u201cis the future\u201d and that all the cool kids are doing it, but obviously, you do not like it. If you did, you would know how to write a simple for loop. Find something you like instead, be great at it, stop wasting your time, and even worst, others\u2019 time!\\n\\nDepending on the level of the position you are applying the questions will vary, but there will be something in common. **Through the questions, I want to understand what kind of knowledge you were able to acquire from your experiences. I need details. It is not the amount of knowledge you have acquired that interests me, it is the ability of actively trying to recognize and acquire that knowledge through the challenges/opportunities that were presented to you.\\n**\\n\\nI want to hear about your personal preferences and opinions about software. Do you have a piece of code that you like to show me and take me through it? Why did you do it with X way instead of Y way? Do you have a favorite editor? Which tools do you use? Do you have a favorite programming language? Why do you like it? Do you have a least-favored programming language? Why do you hate it? Have you done a project that you are proud of? How was the code organized? What challenges did you face? What do you think you could have done better? Are you familiar with functional programming? If yes, do you prefer it over OOP and why?\\n\\n**If your answer to most of the questions above \u2013 or similar ones that I will ask \u2013 is \u201cI haven\u2019t really thought of it\u201d or some other passive answer, then I do not want to work with you.**\\n\\nIn most interviews, there are theoretical questions like, what is OOP? What is a class? What is polymorphism? What is a linked list? What is the difference between stack and heap? What is a binary tree? What is inheritance? What is encapsulation? What is a singleton? What is the difference between merge sort and quick sort? I will not linger a lot on this kind of questions but I will definitely ask a few. To be honest, I do not expect an exact definition from Wikipedia, but I do expect you to be able to give some kind of answer in your own words or through an example. These questions should be easier for a person that just got out of University and has all this theory fresher, but seniors, please, do brush it up a bit as well.\\n\\n**The one thing that I will not be very kind with bad answers is recursion, especially from senior developers.** In fact, I will ask you to implement recursion. The most common exercises with recursion are to find the factorial of a positive number n or calculating a Fibonacci sequence or walking a directory tree. Do not worry about the math in the first two, I will give exact instructions. In fact, you will not need any math knowledge at all. As long as you understand recursion, you will have no problem implementing any of the exercises. If you are a junior candidate and you are not very comfortable with it, please do try without whining that \u201cI am not a mathematician\u201d like someone told me once. There will be no math. I will give you all the definitions and clarifications you need. It\u2019s just another programming problem you need to solve and you will have all the time in the world. JUST TRY.\\n\\n**Although theoretical questions are some kind of indicator, at the same time it does not really show a person\u2019s real experience.** You could have just memorized all the theory, read all the \u201cHow to pass a coding interview\u201d books and manage to succeed with a little bit of luck and by manipulating the interviewer on a weak day. I really don\u2019t understand why a person would do that but it can happen. In fact, some people have the nerve to see how far they can go by trying to fool everybody even after they get hired. That can mostly work in companies with a lot of employees. In small teams the value of their work has a more direct effect and it\u2019s harder to hide.\\n\\nTherefore, **the following part of the interview** will be the most important one. Through real-world** use cases, to show me your experience. To show me that you have tried to solve actual problems and you have bled while doing it.** These can be from \u201cWhat fields would a database table need for a user authentication system?\u201d,  \u201cWhat is the difference between authentication and authorization?\u201c, \u201cWhy would you use a finally clause in a try-catch-finally statement?\u201d, \u201cWhat are some common logger levels?\u201d to very specific ones like \u201cHow do you enter and exit the Node.js REPL?\u201d, \u201cHow do you run the debugger with a keyboard shortcut in your favorite IDE?\u201d.\\n\\nDo you have some specific examples on your own? Even better, please share them with me! **I always enjoy empathizing with the pain and joys that come with software development.** I understand that you are worried that you might not have experience with any of the questions I might ask. I assure you that if you have actually worked on ANY real problem with ANY programming language, framework or technology, we will find some common ground.\\n\\nI wish you good luck!\\n\\nPS: I have humor."},{"id":"my-2020-reads","metadata":{"permalink":"/my-2020-reads","source":"@site/blog/my-2020-reads.md","title":"My 2020 reads","description":"Flow","date":"2020-12-25T00:00:00.000Z","tags":[{"inline":true,"label":"books","permalink":"/tags/books"}],"readingTime":0.88,"hasTruncateMarker":false,"authors":[{"name":"Alexander Lolis","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":null,"page":null}],"frontMatter":{"slug":"my-2020-reads","title":"My 2020 reads","date":"2020-12-25T00:00:00.000Z","author":"Alexander Lolis","author_url":"https://github.com/alolis","author_image_url":"https://avatars.githubusercontent.com/u/82233?v=4","tags":["books"]},"unlisted":false,"prevItem":{"title":"How to pass the first round of my interviews","permalink":"/how-to-pass-the-first-round-of-my-interviews"},"nextItem":{"title":"JavaScript Objects Cachification","permalink":"/javascript-objects-cachification"}},"content":"[![Flow](./assets/book_covers/flow_mihaly_csikszentmihalyi.jpg)](https://www.goodreads.com/book/show/66354.Flow)\\n[![Never split the difference](./assets/book_covers/never_split_the_difference_chris_voss.jpeg)](https://www.goodreads.com/book/show/26156469-never-split-the-difference)\\n[![The Advantage](./assets/book_covers/the_advantage_patrick_lencioni.jpg)](https://www.goodreads.com/book/show/12975375-the-advantage)\\n[![High Output Management](./assets/book_covers/high_output_management_andrew_grove.jpg)](https://www.goodreads.com/book/show/324750.High_Output_Management)\\n[![Conscious Business](./assets/book_covers/conscious_business_fred_kofman.jpg)](https://www.goodreads.com/book/show/1169674.Conscious_Business)\\n[![Poor Charlie\'s Almanack](./assets/book_covers/poor_charlies_almanack_charles_munger.jpg)](https://www.goodreads.com/book/show/944652.Poor_Charlie_s_Almanack)\\n[![The Book of Why](./assets/book_covers/the_book_of_why_judea_pearl.jpg)](https://www.goodreads.com/book/show/36204378-the-book-of-why)\\n[![A philosophy of Software Design](./assets/book_covers/a_philosophy_of_software_design_john_ousterhout.jpg)](https://www.goodreads.com/book/show/39996759-a-philosophy-of-software-design)\\n[![A theory of human motivation](./assets/book_covers/a_theory_of_human_motivation_abraham_maslow.jpg)](https://www.goodreads.com/book/show/36343268-a-theory-of-human-motivation)\\n[![Making Software: What Really Works, and Why We Believe It](./assets/book_covers/making_software_greg_wilson.jpg)](https://www.goodreads.com/book/show/8553359-making-software)\\n[![Elixir In Action](./assets/book_covers/elixir_in_action_sasa_juric.jpg)](https://www.goodreads.com/book/show/38732242-elixir-in-action)\\n[![Disrupted: My Misadventure in the Start-Up Bubble](./assets/book_covers/distrupted_dan_lyons.jpeg)](https://www.goodreads.com/book/show/26030703-disrupted)"},{"id":"javascript-objects-cachification","metadata":{"permalink":"/javascript-objects-cachification","source":"@site/blog/javascript-objects-cachification.md","title":"JavaScript Objects Cachification","description":"Wrapping your JavaScript Objects with caching capabilities","date":"2020-12-19T00:00:00.000Z","tags":[{"inline":true,"label":"development","permalink":"/tags/development"},{"inline":true,"label":"javascript","permalink":"/tags/javascript"},{"inline":true,"label":"nodejs","permalink":"/tags/nodejs"},{"inline":true,"label":"caching","permalink":"/tags/caching"},{"inline":true,"label":"battlefield","permalink":"/tags/battlefield"}],"readingTime":13.27,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":null,"page":null}],"frontMatter":{"slug":"javascript-objects-cachification","title":"JavaScript Objects Cachification","date":"2020-12-19T00:00:00.000Z","description":"Wrapping your JavaScript Objects with caching capabilities","author":"Alexander Lolis","author_url":"https://github.com/alolis","author_image_url":"https://avatars.githubusercontent.com/u/82233?v=4","tags":["development","javascript","nodejs","caching","battlefield"]},"unlisted":false,"prevItem":{"title":"My 2020 reads","permalink":"/my-2020-reads"},"nextItem":{"title":"How to tag data in Redis","permalink":"/how-to-tag-data-in-redis"}},"content":"In one of our backend services, we have a class, that is basically the business model of the service and is used in many locations within the code. At some point, we decided that we need to do some caching since a few methods were doing very expensive calls to other remote services and they didn\u2019t need to occur that often.\\n\\nHow do you add caching to a `class` that is used very often within the rest of the codebase in the least intrusive way? You wrap the `prototype` of the `class` of course! And how do you wrap the prototype of the class? With another function that does the wrapping of course!\\n\\n\x3c!--truncate--\x3e\\n\\nOur main business model (which is just a fancy name for a class that has business logic in it) requires some initialization every time it is instantiated. Therefore, we have a function that initializes and configures an instance of the `BusinessModel` which is used throughout the service. Let\u2019s say that it looks like this:\\n\\n```javascript\\n// Our dummy \'BusinessModel\' ES6 class\\nclass BusinessModel {\\n  findItem() {\\n    // code\\n  }\\n\\n  findItems() {\\n    // code\\n  }\\n\\n  getBasicInfo() {\\n    // code\\n  }\\n}\\n\\n// The utility function that instantiates and initializes a \'BusinessModel\'\\nfunction getBusinessModel() {\\n  const businessModel = new BusinessModel();\\n  \\n  // Do some initialization here and other magic things...\\n\\n  return businessModel;\\n}\\n```\\n\\nSo, the above function is basically being called any time we need an instance of the `BusinessModel` instead of directly constructing it. If for some reason we do not want to wrap the `prototype` and go with another approach instead, this function is the perfect candidate to add caching capabilities to the freshly instantiated `businessModel`. But first things first and more about this later.\\n\\n:::info \\n`class` is not a real boy in JavaScript. It\u2019s just a keyword, not a type. If you are not already aware of this, I strongly recommend reading [You Don\u2019t Know JS: this & Object Prototypes](https://github.com/getify/You-Dont-Know-JS/blob/1st-ed/this%20&%20object%20prototypes/README.md#you-dont-know-js-this--object-prototypes).\\n:::\\n\\nWe will need the code that actually adds caching capabilities to our class so I will just dump it here and try to explain a few things afterward:\\n\\n```javascript\\n\'use strict\';\\n\\nimport _ from \'lodash\';\\nimport objectHash from \'object-hash\';\\n\\nconst debug = require(\'debug\')(\'cachify\');\\n\\nconst KEY_PREFIX_DELIMITER = \':\';\\n\\n/**\\n * @callback preCache\\n * @param {CacheManager} cacheManager - The cache manager instance.\\n * @param {String} cacheKey - The cache key used, including the prefix.\\n * @param {Sting} keyPrefix - The cache key prefix.\\n * @param {String} fnName - The name of the function that was wrapped.\\n * @param {Array} [fnArgs=[]] - The arguments of the function that was wrapped.\\n */\\n\\n/**\\n * @callback postTransformer\\n * @param {*} data - The cached data.\\n */\\n\\n/**\\n * Cachify configuration object.\\n *\\n * @typedef {Object} CachifyOptions\\n * @property {preCache} [preCache=null] - The pre cache hook to call after the original function has been called and\\n *   before the data have been actually cached.\\n * @property {Function} [postTransformer=null] - The post data load transformer hook. Called after the data have\\n *   been loaded from cache.\\n * @property {String|Array|Function} [keyPrefix=cachify] - The default prefix for cache keys. If it is a function\\n *   the first argument of the function will be the context object in which the function was called.\\n */\\n\\n/**\\n * Returns a cache key prefix string.\\n *\\n * @param {String|Array<String>} keyPrefix - The key prefix to use for the cache key.\\n * @returns {String}\\n */\\nfunction getCacheKeyPrefixString(keyPrefix) {\\n  const keyPrefixString = Array.isArray(keyPrefix) ? keyPrefix.join(KEY_PREFIX_DELIMITER) : keyPrefix;\\n\\n  return keyPrefixString;\\n}\\n\\n/**\\n * Returns a cache key which is computed by hashing the target function name and\\n * the target arguments list.\\n *\\n * @param {String|Array<String>} keyPrefix - The key prefix to use for the cache key.\\n * @param {String} fnName - The function name.\\n * @param {Array} fnArgs - The function arguments list.\\n * @returns {String}\\n */\\nfunction getCachifyCacheKey(keyPrefix, name, args) {\\n  const keyPrefixString = getCacheKeyPrefixString(keyPrefix);\\n  const hash = objectHash({name, args}, {replacer});\\n\\n  return ${keyPrefixString}${KEY_PREFIX_DELIMITER}${hash};\\n}\\n\\n/**\\n * Wraps target function with caching capabilities. The wrapped function will always return a promise\\n * since it needs to check the cache first asynchronously and decide whether or not it will call\\n * the original function.\\n *\\n * @param {CacheManager} cacheManager - The cache manager instance.\\n * @param {Function} targetFn - The function we will be wrapping with a caching layer.\\n * @param {CachifyOptions} options - The cachify configuration object.\\n * @returns {Function} - The asynchronous wrapped function.\\n */\\nfunction cachify(cacheManager, targetFn, options = {}) {\\n  const {\\n    keyPrefix = \'cachify\',\\n    postTransformer = null,\\n    preCache = null,\\n    ttl = null\\n  } = options;\\n\\n  const wrappedFn = async function(...args) {\\n    const keyPrefixString = _.isFunction(keyPrefix) ?\\n      getCacheKeyPrefixString(keyPrefix(this)) :\\n      getCacheKeyPrefixString(keyPrefix);\\n\\n    const targetFnName = targetFn.name;\\n    const cacheKey = getCachifyCacheKey(keyPrefixString, targetFnName, args);\\n\\n    const result = await cacheManager.wrap(cacheKey, async () => {\\n      debug({cachify} Calling original function \'${targetFnName}\' with cache key \'${cacheKey}\'...);\\n\\n      const originalResult = await targetFn.apply(this, args)\\n\\n      if (preCache) {\\n        preCache(originalResult, {\\n          cacheManager,\\n          cacheKey,\\n          args,\\n          keyPrefix: keyPrefixString,\\n          fnName: targetFnName\\n        });\\n      }\\n\\n      return originalResult;\\n    }, {ttl});\\n\\n    return postTransformer ? postTransformer(result) : result;\\n  };\\n\\n  return wrappedFn;\\n}\\n\\n/**\\n * Wraps specified methods of the targetObject with caching capabilities.\\n *\\n * **NOTE:** Function mutates `targetObject`.\\n *\\n * @param {CacheManager} cacheManager - The cache manager instance.\\n * @param {Object} targetObject - The object we will be wrapping.\\n * @param {Object} cacheableMap - The object describing which methods of `targetObject` should be wrapped.\\n * @param {CachifyOptions} [options={}] - The cachify options object.\\n * @returns {Object} - The cachified object.\\n */\\nfunction cachifyObject(cacheManager, targetObject, cacheableMap, options = {}) {\\n  _.forEach(cacheableMap, (functionConfig, functionName) => {\\n    if (!functionConfig) {\\n      debug(`{cachifyObject} Cachification for function \'${functionName}\' is disabled...skipping...`);\\n\\n      return;\\n    }\\n\\n    const originalFn = targetObject[functionName];\\n\\n    if (!originalFn) {\\n      debug(`{cachifyObject} Couldn\'t find function \'${functionName}\' on target object...skipping...`);\\n\\n      return;\\n    }\\n\\n    const functionOptions = {...options, ...(_.isPlainObject(functionConfig) ? functionConfig : {})};\\n    const wrappedFn = cachify(cacheManager, originalFn, functionOptions);\\n\\n    targetObject[functionName] = wrappedFn;\\n  });\\n\\n  return targetObject;\\n}\\n```\\n\\nA few things are going on in the code block above. You do not need to use everything but I have added them anyway because we will need them in a later post for a caching approach I will describe. Besides, they might help you with your own use case!\\n\\n### Using hashes for cache keys\\n\\n```javascript\\nfunction getCachifyCacheKey(keyPrefix, fnName, fnArgs) {\\n  const keyPrefixString = getCacheKeyPrefixString(keyPrefix);\\n\\n  const hash = objectHash({name: fnName, args: fnArgs}, {replacer});\\n\\n  return `${keyPrefixString}${KEY_PREFIX_DELIMITER}${hash}`;\\n}\\n```\\n\\nThe most important thing from the whole code is the way we generate our cache keys within the `getCachifyCacheKey` function. If you look more closely above, we are creating a hash from the name and the arguments of the function we want to cachify and the [object-hash](https://www.npmjs.com/package/object-hash) npm module helps us do just that.\\n\\nThe reason we do this is the fact that **we want to be able to cache results from the same function, but with different arguments, to separate cache keys**. if something simpler was used as a cache key (e.g. the function name), then we would be returning the same cached value all the time, no matter the arguments we would be passing to the function, which is not something we want.\\n\\nFor example, the following two **same** method calls will produce two different cache keys due to the fact that they have different arguments:\\n\\n```javascript\\n// Cache key: b1e2f1cbcf8a99de6bbeea579d980cc0b0f3261a\\nbusinessModel.findItems({isHidden: false});\\n\\n// Cache key: 493b0e3045532ab6effe912e71feb7ee26c29199\\nbusinessModel.findItems({isHidden: true});\\n```\\n\\n### The main functions; `cachify` and `cachifyObject`\\n\\n`cachify` is the function that does the main work. It will wrap a target function with caching capabilities by internally using the [cache-manager](https://www.npmjs.com/package/cache-manager) npm module. You do not really need this module for the wrapping, you could also use a lower-level library like [ioredis](https://www.npmjs.com/package/ioredis) and do the wrapping yourself. However, in our use case, we needed `cache-manager` so I used that instead. Besides, it comes with a handy method called **wrap** which is what we need.\\n\\n```javascript\\n// Version with \'cache-manager\'\\nfunction cachify(cacheManager, targetFn, options = {}) {\\n  // [removed code for simplicity]\\n  \\n  const wrappedFn = async function(...args) {\\n    // [removed code for simplicity] \\n\\n    const result = await cacheManager.wrap(cacheKey, async () => {\\n      const originalResult = await targetFn.apply(this, args);      \\n  \\n      return originalResult;\\n    }, {ttl});\\n\\n    // [removed code for simplicity]\\n  }\\n\\n  // The \'wrappedFn\' which we will return is going to be asynchronous, no matter what\\n  return wrappedFn;\\n}\\n\\n/*\\n  Alternative version without \'cache-manager\' but with \'ioredis\' instead. \\n  It could be done better, but just giving you an idea what might look like. \\n  It will basically check if the cache key exists by loading it, and if not, \\n  it will call the original function and cache the result before it actually \\n  returns it. Easy to implement yourself as well in case you do not go \\n  with \'cache-manager\'.\\n*/\\nfunction cachify(redis, targetFn, options = {}) {\\n  // [removed code for simplicity]\\n  \\n  const wrappedFn = async function(...args) {\\n    // [removed code for simplicity] \\n\\n    const cachedResult = await redis.get(cacheKey);\\n\\n    if (cachedResult) {\\n      return JSON.parse(cachedResult); \\n    } else {\\n      const originalResult = await targetFn.apply(this, args);\\n\\n      const originalResultString = JSON.stringify(originalResult);\\n      ttl ? await redis.setex(originalResultString, ttl) : await redis.set(originalResultString);\\n  \\n      return originalResult;\\n    }\\n\\n    // [removed code for simplicity]\\n  }\\n\\n  // The \'wrappedFn\' which we will return is going to be asynchronous, no matter what\\n  return wrappedFn;\\n}\\n```\\n\\nThe partial code above from the `cachify` function shows the current cache wrapping approach and a possible alternative.\\n\\nOne thing that we must note here is the use of `await` in order to communicate with the cache. That means, that even if the original function \u2013 the one we are wrapping \u2013 was not asynchronous, then it must be converted to one (by using `async` as shown above) in order for the mechanism to work properly.\\n\\nI am pretty sure that in the full code at the beginning you have noticed other things already, like `preCache` and `postTransformer` hooks. Although they are not really necessary for this post, as you have already guessed they definitely have their use if you want to make more actions before and after caching the data. **Hint:** managing a [redis secondary index](how-to-tag-data-in-redis.md#using-sets-as-secondary-indexes). If your own use case needs it, you could introduce more hooks into the code.\\n\\n`cachifyObject` is more like a helper function in order to easily cachify an `Object`. It will loop the object and based on a map describing which methods of the object we want to `cachify`, it will do it for us by using cachify internally.\\n\\nThe original methods will be overwritten and the mutated target `Object` will be returned to the caller\\n\\n### Bringing everything together\\n\\nThe hard part is done, we have our wrapping functions ready and all we need now is to apply it to the `prototype` of the `class` we want to cachify; in our case, the `BusinessModel`.\\n\\n```javascript\\n\'use strict\';\\n\\nimport {getRedisSingletonInstance} from \'/some/magic/utils/we/have\';\\nimport {BusinessModel} from \'/some/magic/models/we/have\';\\nimport CacheManager from \'cache-manager\';\\nimport redisStore from \'cache-manager-ioredis\';\\n\\nfunction cachifyBusinesModel(businessModel, {ttl = 1200} = {}) {\\n  const options = {\\n    ttl,\\n    keyPrefix: \'businessModel\'\\n  };\\n\\n  // The methods in this map will be targeted for cachification. \\n  // Any methods that are not in this map will be left intact.\\n  // We also make use of postTransformer in order to convert our cached \\n  // results to BusinessModel instances before returning.\\n  const cacheableMethodsMap = {\\n    findItems: {\\n      postTransformer: result => _.map(result, item => BusinessModel.fromJson(item)\\n    },\\n    findItem: {\\n      postTransformer: result => BusinessModel.fromJson(result)\\n      ttl: 120 // Override default ttl\\n    },\\n    getBasicInfo: true\\n  };\\n\\n  const cacheManager = CacheManager.caching({\\n    store: redisStore,\\n    redisInstance: getRedisSingletonInstance(),\\n    isCacheableValue: value => value !== null && value !== false && value !== undefined\\n  });\\n\\n  return cachifyObject(cacheManager, businessModel, cacheableMethodsMap, options);\\n}\\n\\n// Keep the cachification call near our \'getBusinessModel\' utility function\\n// and maybe with some explanatory comment block in order for someone new\\n// to easily figure out what is going on.\\ncachifyBusinesModel(BusinessModel.prototype);\\n\\n// Make sure that you mention in the comment block here that the result \\n// is cachified and point out to the reader to the correct direction in order \\n// to find more details about it. \\nfunction getBusinessModel() {\\n  const businessModel = new BusinessModel();\\n  \\n  // Do some initialization here...\\n\\n  return businessModel; // Our businessModel instance is now cachified!\\n}\\n```\\n\\nA few things I would like to note here for the code above:\\n\\n1. We have implemented a `cachifyBusinesModel` function in which we will be cachifying the `businessModel` Object we pass as an argument. A `map` named `cacheableMethodsMap` contains all the methods that we want to cachify and it will be passed along with some other options (like the cache key) to our `cachifyObject` function.\\n2. We initializate a `CacheManager` instance which we will pass to our cachifyObject function as well. The options of the `CacheManager` are not important. What is important is how we get the redis instance. As you have noticed we use a `getRedisSingletonInstance` function which basically returns a global instance of redis that will be instantiated the first time the function is called. For every other call, the existing instance will be returned. This is important in order to avoid any code bottleneck by instantiating redis again and again everytime `cachifyBusinesModel` function is called. If we wrap the prototype, as we do in the example above, then it shouldn\u2019t be a problem since it will only be called once. But if you go with the alternative approach (described in the next section) which wraps the instantiated object instead, then it will definitely be an issue.\\n3. Make sure that you comment on everything in your code in order for the caller of the `getBusinessModel` to know exactly where he is getting into.\\n\\n:::info\\nInstead of implementing `getRedisSingletonInstance` to handle the singleton, you could use a [container](https://www.npmjs.com/package/typedi) approach.\\n:::\\n\\n### To `prototype` or not to `prototype`\\n\\nI have mentioned earlier the use of a utility function, `getBusinessModel` in which the `BussinessModel` is instantiated and initialized there. The reason that I did mention this function is because I want to point out that wrapping the `prototype` has a trade-off; code obscurity.\\n\\nA new guy might miss the fact that *some* of the object methods he uses return a cached version of the result. One might say that we can add a suffix to those methods (e.g. `findItemsWithCache`) instead of overwriting the originals. Except that I find this ugly, you will also not be able to easily disable the cache in case you want to do some debugging without it. By keeping the original names, you can just turn off cachification in case you want to run the code without the cache and just let it do its thing without the hassle of changing method names as well.\\n\\nAnother small problem with the wrapping of the `prototype` is when we need to dynamically build our cache key prefix. If we want to use variables that are not within the object we are wrapping (which we can access them via this if we use a function as a `keyPrefix` getter) and we can not know their values beforehand, then we simply can\u2019t do it. To be fair here, we are doing some complex caching ourselves and we haven\u2019t bumped in such a case but it\u2019s definitely a possibility.\\n\\nA possible alternative, as you can see in the code example below, is to do the wrapping every time the `BusinessModel` is instantiated:\\n\\n```javascript\\n// Alternative version with cachifying the instantiated object. \\n// No obscurity with this version; just \'useCache\' a flag that the caller \\n// decides if it should be true or false. The new guy will be happier.\\nfunction getBusinessModel({useCache = true} = {}) {\\n  const businessModel = new BusinessModel();\\n  \\n  // Do some initialization here...\\n\\n  if (useCache) {\\n    return cachifyBusinessModel(businessModel);\\n  } else {\\n    return businessModel;\\n  }\\n}\\n```\\n\\nHowever, if you have a large amount of objects that you are instantiating, you will definitely benefit from wrapping the `prototype` _once_ instead of wrapping each instantiated object as it might become a bottleneck for your code.\\n\\nIf you have a very small amount of objects that you are instantiating, it might be better to use the alternative version of `getBusinessModel` from above which will also be doing the cachification. The advantage of going with this approach, even if there is a slight \u2013 almost insignificant probably \u2013 performance penalty, the code will be much less obscured. The new guy will just need to read the documentation of the function and immediately will figure out what is going on without getting crazy first!\\n\\n### Conclusion\\n\\nWe saw that with the use of a couple of functions, we can easily add caching to expensive `Object` methods that we use often with minimum effort. Depending on our use case, and if our code is modular enough, we can achieve the same result in more than one way. I hope that I gave you some idea of how to approach this and maybe you can find improvements while you are at it. If you do, I would love to hear about them!"},{"id":"how-to-tag-data-in-redis","metadata":{"permalink":"/how-to-tag-data-in-redis","source":"@site/blog/how-to-tag-data-in-redis.md","title":"How to tag data in Redis","description":"What are Sets and how to use them as secondary indexes","date":"2020-12-01T00:00:00.000Z","tags":[{"inline":true,"label":"playground","permalink":"/tags/playground"},{"inline":true,"label":"howto","permalink":"/tags/howto"},{"inline":true,"label":"redis","permalink":"/tags/redis"}],"readingTime":5,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":null,"page":null}],"frontMatter":{"slug":"how-to-tag-data-in-redis","title":"How to tag data in Redis","date":"2020-12-01T00:00:00.000Z","description":"What are Sets and how to use them as secondary indexes","author":"Alexander Lolis","author_url":"https://github.com/alolis","author_image_url":"https://avatars.githubusercontent.com/u/82233?v=4","tags":["playground","howto","redis"]},"unlisted":false,"prevItem":{"title":"JavaScript Objects Cachification","permalink":"/javascript-objects-cachification"},"nextItem":{"title":"Fight or flight? Breathe instead","permalink":"/fight-or-flight-breathe-instead"}},"content":"[Redis](https://redis.io/) is a wonderful piece of technology. An in-memory, super-fast key-value database, which if you do not already know that it exists, you have been living under a rock.\\n\\nThe cool thing about Redis, is that it supports more data types than simply storing string key-value pairs, and that\u2019s when the fun begins. One of those data types, which will help us with our tagging exercise, is Sets.\\n\\n\x3c!--truncate--\x3e\\n\\n### Redis Sets\\n\\nLet\u2019s assume that you have an app and you want to show a list of book titles and their associated tags. The first step is to add those articles in Redis, along with their tags. Let\u2019s add a few via `redis-cli`:\\n\\n```bash\\n127.0.0.1:6379[1]> SADD \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\" business leadership nonfiction patrick_lencioni\\n(integer) 4\\n\\n127.0.0.1:6379> SADD \\"Conscious Business: How to Build Value Through Values\\" business nonfiction fred_kofman\\n(integer) 3\\n\\n127.0.0.1:6379> SADD \\"Code Complete\\" programming computer_science reference steve_mcconnell\\n(integer) 4\\n```\\n\\nThe above commands will create three different `Sets`. Each of them will use the title of the book as a key and the rest of the values after the title will be added as members within each Set.\\n\\nYou can check the members of the `Set` by issuing an `SMEMBERS` command, like so:\\n\\n```bash\\n127.0.0.1:6379[1]> SMEMBERS \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\"\\n1) \\"business\\"\\n2) \\"leadership\\"\\n3) \\"nonfiction\\"\\n4) \\"patrick_lencioni\\"\\n```\\n\\nThe special thing about `Sets` is that if you try to add an element that already exists, the element will simply be ignored. This ensures that every member within that Set, is unique.\\n\\nFor example, let\u2019s say you want to add the tag `must_read` to a `Set`, and then you try to re-add it:\\n\\n```bash\\n127.0.0.1:6379[1]> SADD \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\" must_read\\n(integer) 1\\n\\n127.0.0.1:6379[1]> SADD \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\" must_read\\n(integer) 0\\n\\n127.0.0.1:6379[1]> SMEMBERS \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\"\\n1) \\"business\\"\\n2) \\"must_read\\"\\n3) \\"leadership\\"\\n4) \\"nonfiction\\"\\n5) \\"patrick_lencioni\\"\\n```\\n\\nAs you can see in the example above, even though I tried to add it twice, there is only one copy of the `must_read` tag within the `Set`, which definitely makes our next step easier.\\n\\n### Using Sets as secondary indexes\\n\\nStoring plain `Sets` is not that useful by itself. Most of the time, we will need to access the data in different ways in order to show a useful representation of said data. By denormalizing and/or duplicating the data we are able to achieve just that. This common pattern, called \\"secondary index\\", in our case is basically a Set with the original data, but inverted.\\n\\nFor example, let\u2019s say that you want to be able to find all the book titles with the tag *business*. What you need to do here is to create a `Set` whose key will be `tag:business` and its members are going to be the titles of the books which are associated with this tag:\\n\\n```bash\\n127.0.0.1:6379> SADD tag:business \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\" \\"Conscious Business: How to Build Value Through Values\\"\\n(integer) 2\\n\\n127.0.0.1:6379> SADD tag:programming \\"Code Complete\\"\\n(integer) 1\\n```\\n\\nNow every time you need to find all books with the *business* tag, all you have to do is to use the `SMEMBERS` command on the `tag:business` key, and then use those members (which are basically keys that represent other `Sets`, book titles in our case) to get the complete list of their tags:\\n\\n```bash\\n127.0.0.1:6379> SMEMBERS tag:business\\n1) \\"Conscious Business: How to Build Value Through Values\\"\\n2) \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\"\\n\\n127.0.0.1:6379> SMEMBERS \\"Conscious Business: How to Build Value Through Values\\"\\n1) \\"business\\"\\n2) \\"fred_kofman\\"\\n3) \\"nonfiction\\"\\n\\n127.0.0.1:6379> SMEMBERS \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\"\\n1) \\"business\\"\\n2) \\"patrick lencioni\\"\\n3) \\"nonfiction\\"\\n4) \\"leadership\\"\\n5) \\"must_read\\"\\n```\\n\\nOf course, the above is just a basic idea of what you can do with a secondary index. Properly creating and maintaining those secondary indexes is definitely something you need to carefully consider in your application logic since Redis will not handle it for you.\\n\\nAnother thing that you need to consider is atomicity. If multiple processes want to update your secondary indexes but also use any intermediate values from Redis in order to calculate the new data for the update, then the only way to achieve this is with [Lua scripting](https://redis.io/commands/eval) or else you will probably end up with inconsistencies. More on that in a different post!\\n\\nFinally, keep in mind here that if you have A LOT of members in the `Set`, that might slow things down and you will need to use `SCAN` (or another closely related command) instead.\\n\\n### Other cool things with Sets\\n\\nFinding common tags between book titles:\\n\\n```bash\\n127.0.0.1:6379> SINTER \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\" \\"Conscious Business: How to Build Value Through Values\\"\\n1) \\"business\\"\\n2) \\"nonfiction\\"\\n```\\n\\nFinding ALL unique tags between book titles:\\n\\n```bash\\n127.0.0.1:6379> SUNION \\"The Advantage: Why Organizational Health Trumps Everything Else in Business\\" \\"Conscious Business: How to Build Value Through Values\\"\\n1) \\"leadership\\"\\n2) \\"business\\"\\n3) \\"fred_kofman\\"\\n4) \\"must_read\\"\\n5) \\"nonfiction\\"\\n6) \\"patrick lencioni\\"\\n```\\n\\nFinding a random book title with a specific tag:\\n\\n```bash\\n127.0.0.1:6379> SRANDMEMBER tag:business\\n\\"Conscious Business: How to Build Value Through Values\\"\\n```\\n\\n### Conclusion\\n\\nSets are definitely a powerful and helpful data structure in Redis which can be the building block for many more things. With the use of secondary indexes, we can build and execute [even more complex](https://redis.io/topics/indexes) queries on our data and then load them in a very very fast manner. As we will be digging deeper, and by elevating the capabilities of Redis, we can build a very fast and efficient caching mechanism, even for the most demanding apps."},{"id":"fight-or-flight-breathe-instead","metadata":{"permalink":"/fight-or-flight-breathe-instead","source":"@site/blog/fight-or-flight-breathe-instead.md","title":"Fight or flight? Breathe instead","description":"How to achieve the best attitude at work with integrity and self-awareness","date":"2020-11-04T00:00:00.000Z","tags":[{"inline":true,"label":"business","permalink":"/tags/business"},{"inline":true,"label":"culture","permalink":"/tags/culture"},{"inline":true,"label":"teams","permalink":"/tags/teams"}],"readingTime":9.82,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":null,"page":null}],"frontMatter":{"slug":"fight-or-flight-breathe-instead","title":"Fight or flight? Breathe instead","date":"2020-11-04T00:00:00.000Z","description":"How to achieve the best attitude at work with integrity and self-awareness","author":"Alexander Lolis","author_url":"https://github.com/alolis","author_image_url":"https://avatars.githubusercontent.com/u/82233?v=4","tags":["business","culture","teams"]},"unlisted":false,"prevItem":{"title":"How to tag data in Redis","permalink":"/how-to-tag-data-in-redis"},"nextItem":{"title":"Remote work tips - How NOT to snap","permalink":"/remote-work-tips"}},"content":"We\u2019ve all been there. Feeling the frustration, the unfairness, and the negativity consuming us while everything is getting out of our control.\\n\\nEmotions take over your brain and you are suddenly overwhelmed by your own feelings, leaving no room for rational thinking. That\u2019s when your flight or fight response kicks in.\\n\\nThanks to amygdala hijacking, rational thinking becomes very difficult, and smashing a chair on someone\u2019s face or storming out of a meeting room becomes very tempting. But please, do not do it, and instead, take a **DEEP breath** in order to make the first step into regaining consciousness.\\n\\n\x3c!--truncate--\x3e\\n\\nIn his excellent book, [Conscious Business](https://www.goodreads.com/book/show/1169674.Conscious_Business), Fred Kofman talks about the importance of bringing awareness to our (business) lives by recognizing other people\u2019s needs as well as ours and seeing their perspective without taking things personally or handling situations by putting our ego first. By **maintaining a more open attitude**, we are able to see everything as a challenge, as a chance to grow, instead of getting immediately defensive and feeling like a victim. This helps us to get better in our daily interaction with other human beings, and embrace a \u2018player attitude\u2019 in which instead of throwing the blame in any direction to avoid solving the problem because this seems easier, we become part of the solution by owning it.\\n\\nSo, what the hell is that Fred dude saying that this blog dude is agreeing with? To own up for other people\u2019s mistakes? To try solving every problem that the company has and be happy about it? To be a \u201cyes\u201d person? To put up a smile while everyone is being aggressive and expressing opinions that have no merit?\\n\\nNope. What I am saying is, that, **at the end of the day the only thing you have is your integrity and your values**. No matter what is thrown at you, you will always be left with a positive and proud feeling about yourself, because you chose the right attitude; you stood by your values, handled the situation with openness and maintained your integrity. Even if the outcome was bad.\\n\\nWhat is the right attitude you may ask? The following will \u2013 probably \u2013 give you an idea of the direction you need to go. It\u2019s definitely not easy and I am still working on it myself!\\n\\n### Taking responsibility. For everything\\n\\nTaking responsibility does not apply only in situations in which you were personally involved; it rather stands for any situation that might come up and calls for action. It\u2019s about reacting and trying to solve the problem at hand. Even if that does not necessarily guarantee success, you should see it as a challenge where you can influence the result instead of walking away while saying to yourself that \u201cit\u2019s not my problem\u201d.\\n\\n**Choosing to act, even if everything fails, will always be a self-empowering move rather than choosing to do nothing about it and allow the failure to just happen.**\\n\\nDon\u2019t get me wrong; Of course, I understand that this is not always fair and that people should just do their damn job and everybody will have one less thing to worry about. But\u2026life is not fair, and people act stupidly. Even worse, they choose apathy very often. So, instead of feeling resentment and resignation all the time, I **choose** to act whenever I can and do not bitch about it. Any other alternative is simply not good enough for me.\\n\\nHowever, the above is not meant to be used as an excuse when things go sideways. There is a huge and obvious difference between honestly **striving for excellence** by wholeheartedly doing your best and when you are doing the \u201coh well, at least I tried my best\u201d self-assuring routine.\\n\\n### Your truth is not my truth. Help me understand you\\n\\nEach of us has our own mental model (a representation of the world, that is) which is shaped based on our knowledge, our personal experiences, and our culture. As soon as you realize that everybody has their own perspective and yours is just a version of the truth, you will better handle any future human interaction. Try to see the other person\u2019s perspective and try to create a shared truth which will serve as the common ground for any productive conversation.\\n\\n**Don\u2019t get caught up in trying to enforce your truth**, this is just a controlling attitude that will get you nowhere and hurt the relationship with the other person \u2013 and basically make you an unlikable douche.\\n\\nIf you are doing the listening, the first thing you need to do is to **shut up** and actually listen. **ACTUALLY LISTEN**. Do not shut down because you are too eager to respond. Your turn will come but until then be present, be open, and try to connect with the speaker. **Acknowledge** what the other person just said/felt and try to summarize it in order to ensure that you understood correctly. Even if for some reason you start feeling defensive and slowly getting angry, snap out of it and **start an inquiry** instead. This will help you understand better why is that what they are saying has put you on the defensive in the first place and provide you with a new perspective. Finally, make sure that the speaker has **nothing else to add** before you actually start replying. Manners!\\n\\nIf you are doing the speaking, **make sure that you have a beginning, a middle, and an end**, or else mumbling without the slightest trail of thought will exhaust the listener and you will lose their attention. **Do not waste your listeners time** by whining about [insert topic here] or petty annoyances. Instead, **state your ideas/opinions, provide facts** by supporting them with the appropriate research or observations, and **recommend a course of action**. In this way, the conversation will always have **one direction;** _forward_. **Watch your listener\u2019s reactions** and **ask questions** to make sure they actually understood what you are trying to say. Last but not least, **welcome any feedback** and **do not get defensive**, even if that feedback challenges you. This is how both of you will learn something new from this conversation and make a step closer to an actual solution.\\n\\n### Stop resisting. Challenge the reasons behind your opinions and your actions\\n\\nSometimes it\u2019s hard to understand the real reasons why another person acts the way they do but it\u2019s even harder to understand our own reasoning behind our own actions.\\n\\nYou need to **ask yourself** whether your opinions and your actions (or lack thereof) are based on your own personal gain/convenience or if you have your team\u2019s/company\u2019s best interest at heart.\\n\\nTake a breath and **create some space from your emotions** (without suppressing them) in order to try to observe and understand what is going on within yourself and why you acted the way you did. The more time you give to this observation of self, the more self-aware you become and more able to reflect upon your feelings and your actions. As a result, you have a **more objective perspective** of yourself, and of course, more control.\\n\\n**Think globally, not locally**. Think long-term, not short-term. You are part of a larger community that shares a common goal, to fulfill the mission of the organization. Never lose sight of that and you will keep yourself in check and be more objective in a much easier way than you think.\\n\\n### There is no \u201cyou\u201d or \u201cthey\u201d. It\u2019s \u201cI\u201d or \u201cwe\u201d\\n\\nOne of the things I despise the most (note to self: figure out why) is when someone within the organization, or even worst within the same team, tries to distance themselves from a problem by avoiding self-statements.\\n\\nBy using the subject \u201cyou\u201d instead of \u201cI\u201d or \u201cthey\u201d instead of \u201cwe\u201d during a discussion, you create a negative experience for everyone involved. **Non-self-statements imply blame and foster criticism** towards others which in turn puts them into a defensive mood. If that does not ruin the discussion, it will definitely make it harder to continue smoothly and everyone sooner or later will start feeling a psychological drag.\\n\\nThe ironic thing about self-statements however, is that **the person who avoids them _is the one being defensive_ in the first place**. Even though that person wants to be part of the solution, they do not understand that they must first embrace the problem as a member of the same team, mostly due to insecurity or emotional pressure for other reasons (even unknown to them most of the time).\\n\\n### Self-actualization. Infinite motivation\\n\\n> A musician must make music, an artist must paint, a poet must write, if he is to be ultimately happy. What a man can be, he must be. This need we may call self-actualization.\\n> \\n> Abraham H. Maslow\\n\\nWhat makes a top athlete to keep training even though they are already the best at what they do? What makes a top violinist keep practicing even though they have already mastered the toughest compositions? **What motivates any of the people we admire** to become something more and better from what they already are?\\n\\nThey do not do it for the money, the fame, or any other self-limiting reason. These are simply measures of achievement at this point. They do it because they want to. They play the game for the sake of the game and they try to get a little bit better every day because **the need to improve and to keep testing themselves has no limit.**\\n\\nThe good news is that you do not need to be the best of the best in a field in order to reach your full potential. Based on Abraham Maslow, what motivates a person is a [hierarchy of needs](https://en.wikipedia.org/wiki/Maslow%27s_hierarchy_of_needs). In short, when a more basic or psychological need is satisfied, we are no longer motivated by it and we need to change level in order to find motivation again. Of course, a person can have concurrent needs, but one of them is always stronger than the rest and it is the one that drives us. The order of our needs does not need to be progressive either. **By deciding what is really important to you, and by conquering all your lower needs first, you can finally arrive at the only level of infinite source of motivation, creativity, and your highest level of performance; self-actualization.**\\n\\nWe spend a large part of our lives at work and that work must offer something more than just money. It has to be able to offer some sense of fulfillment. To be in a safe place where you can stretch your limits, to be able to challenge yourself, to test your character and skill. **Do not waste your life in a working environment that pays the bills but only makes you sad and miserable every day.**\\n\\n### Be a pro at least\\n\\nEven if you are not really motivated to embark on this psychological and emotional trip, even if you feel that it\u2019s pointless to try and make your working environment a better place for everyone, then let me make it brutally simple for you; **you are a professional**, and you need to act accordingly within your workplace and respect its culture. If you are not satisfied, **instead of creating noise and drama**, do yourself and everyone else a favor and simply move on to somewhere else where you feel that it will be a better fit for you.\\n\\nBut I think that you can do better than that.\\n\\n**Take the trip instead**, because, even though achieving emotional mastery is not easy, its effects are reflected upon you and the ones around you much sooner than you think."},{"id":"remote-work-tips","metadata":{"permalink":"/remote-work-tips","source":"@site/blog/remote-work-tips.md","title":"Remote work tips - How NOT to snap","description":"Lot of these articles going around these days due to COVID-19, but I felt like giving my two cents since I\u2019ve been a freelancer in the past, mostly working from home, so I know how it feels like.","date":"2020-04-18T00:00:00.000Z","tags":[{"inline":true,"label":"self-help","permalink":"/tags/self-help"},{"inline":true,"label":"remote-work","permalink":"/tags/remote-work"},{"inline":true,"label":"lifestyle","permalink":"/tags/lifestyle"}],"readingTime":2.86,"hasTruncateMarker":true,"authors":[{"name":"Alexander Lolis","url":"https://github.com/alolis","imageURL":"https://avatars.githubusercontent.com/u/82233?v=4","key":null,"page":null}],"frontMatter":{"slug":"remote-work-tips","title":"Remote work tips - How NOT to snap","date":"2020-04-18T00:00:00.000Z","author":"Alexander Lolis","author_url":"https://github.com/alolis","author_image_url":"https://avatars.githubusercontent.com/u/82233?v=4","tags":["self-help","remote-work","lifestyle"]},"unlisted":false,"prevItem":{"title":"Fight or flight? Breathe instead","permalink":"/fight-or-flight-breathe-instead"}},"content":"Lot of these articles going around these days due to COVID-19, but I felt like giving my two cents since I\u2019ve been a freelancer in the past, mostly working from home, so I know how it feels like.\\n\\nDespite what everyone thinks about the awesomeness of working from the comfort of your couch, it\u2019s definitely not easy. \u0391fter a while, no matter how many tips you are going to read, it\u2019s up to you to try and achieve mental toughness.\\n\\n\x3c!--truncate--\x3e\\n\\nThe following is a small list of what works for me, and might work for you as well, but in the end everyone does their own thing to stay focused.\\n\\n### Keep.a.routine.at.all.times.\\n\\nAlthough it sounds tempting to be in your PJs all day long, it is bad for your mentality since it will make you feel and act lazy. You need to maintain a routine as if you were going to a workspace outside your home.\\n\\nChange your clothes. No need to dress in something formal but do not stay in your PJs. Follow your morning routine, make a small breakfast and some coffee or whatever else you usually do and start working. Persuade that brain of yours that you are not on vacation and try to be productive even if that [insert procrastination reason here] looks tempting.\\n\\n### Set ground rules with the people in your space.\\n\\nIf you live with other people make it clear to them that they need to act like you are not there. They should not annoy you even for the slightest thing, because, you are not really there.\\n\\n### Maintain regular hours. Take breaks. Leave home.\\n\\nDon\u2019t overdo it with work or else you will burn out very fast and the endgame here is the long run, not a few days in overdrive. Do not skip lunch breaks. Spend 45 minutes \u2013 1 hour to it and use it as a chance to relax a bit. In the afternoon, go out for a short walk/running and empty your mind. I understand that there will be days which extra work is required but in order to have that extra energy you need to take good care of yourself and respect your limits.\\n\\n### Keep a dedicated and clean office space.\\n\\nThe important thing here is to use a different **space** for work and a different one for relaxing in order for you to associate it with different mind states. If you have a separate room, then that\u2019s great. If not, it\u2019s still ok. Like I said, it\u2019s about mind states. Find the spot in your house that helps you get \u201cin the zone\u201d and keep it clean and tidy.\\n\\n### Socialize with colleagues. Over-communicate.\\n\\nRemote work can create a distance between you and your colleagues, making it hard to be \u201cin the loop\u201d for things that might be happening in the office. It\u2019s lucky for us that nowadays there are a lot of tools to help us communicate with other people in a more direct and live manner. Use these tools and if your company does not already have them then request from the person in charge to choose one for your organization. Keep in touch with your team every day and even try to make time for small talk.\\n\\nAnd remember, consider yourself lucky during this crisis that you can work for your company from home. A lot of people cannot, since their physical presence is required."}]}}')}}]);